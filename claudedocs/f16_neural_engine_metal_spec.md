# ãƒ†ãƒ³ã‚½ãƒ«ãƒ­ã‚¸ãƒƒã‚¯: f16 + Neural Engine + Metal ä»•æ§˜

## è¨­è¨ˆæ–¹é‡

### ã‚³ã‚¢åŸå‰‡
1. **f16ã‚ªãƒ³ãƒªãƒ¼**: ã™ã¹ã¦ã®æµ®å‹•å°æ•°ç‚¹æ¼”ç®—ã¯f16 (half precision)
2. **GPUæœ€å„ªå…ˆ**: å¯èƒ½ãªé™ã‚ŠMetal/Neural Engineã§å®Ÿè¡Œ
3. **ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼**: Neural Engine â†” Metalé–“ã§ãƒ‡ãƒ¼ã‚¿å¤‰æ›ãªã—
4. **CPUæœ€å°åŒ–**: æ¡ä»¶åˆ†å²ãªã©ã®åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã®ã¿CPUä½¿ç”¨

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£éšå±¤

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  TensorLogic Language Layer             â”‚
â”‚  (Parser, AST, Type System)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Execution Engine (CPU - Control Only)  â”‚
â”‚  - Rule evaluation                      â”‚
â”‚  - Conditional branching                â”‚
â”‚  - Memory orchestration                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â†“
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â†“                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Neural Engineâ”‚      â”‚    Metal     â”‚
â”‚  (CoreML)    â”‚â†â”€â”€â”€â”€â†’â”‚   (f16 ops)  â”‚
â”‚              â”‚ f16  â”‚              â”‚
â”‚ - Inference  â”‚ zero â”‚ - Basic ops  â”‚
â”‚ - MatMul     â”‚ copy â”‚ - Custom     â”‚
â”‚ - Conv       â”‚      â”‚   kernels    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## 1. ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿å‹ (f16å°‚ç”¨)

### 1.1 ãƒ†ãƒ³ã‚½ãƒ«å‹

```rust
use half::f16;

#[repr(C)]
pub struct Tensor {
    // ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ (CPU)
    shape: Vec<usize>,
    strides: Vec<usize>,

    // ãƒ‡ãƒ¼ã‚¿æœ¬ä½“ (GPU)
    buffer: BufferHandle,

    // ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
    device: Device,

    // è‡ªå‹•å¾®åˆ†ç”¨
    grad: Option<Box<Tensor>>,
    requires_grad: bool,
}

pub enum BufferHandle {
    Metal(MetalBuffer),
    NeuralEngine(MLMultiArray), // CoreML
}

pub enum Device {
    Metal(MetalDevice),
    NeuralEngine,
    CPU, // åˆ¶å¾¡ãƒ•ãƒ­ãƒ¼ã®ã¿
}
```

### 1.2 Metal ãƒãƒƒãƒ•ã‚¡

```rust
pub struct MetalBuffer {
    buffer: metal::Buffer,      // MTLBuffer
    length: usize,              // è¦ç´ æ•°
    device: metal::Device,      // MTLDevice
}

impl MetalBuffer {
    // f16ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥Metalãƒãƒƒãƒ•ã‚¡ã«æ›¸ãè¾¼ã¿
    pub fn from_f16_slice(device: &metal::Device, data: &[f16]) -> Self;

    // Metalãƒãƒƒãƒ•ã‚¡ã‹ã‚‰f16ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿å‡ºã—
    pub fn to_f16_vec(&self) -> Vec<f16>;

    // ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã§NeuralEngineãƒãƒƒãƒ•ã‚¡ã«å¤‰æ›
    pub fn as_mlmultiarray(&self, shape: &[usize]) -> MLMultiArray;
}
```

### 1.3 Neural Engine ãƒãƒƒãƒ•ã‚¡

```rust
use coreml::MLMultiArray;

pub struct NeuralEngineBuffer {
    array: MLMultiArray,  // MLMultiArray (Float16)
}

impl NeuralEngineBuffer {
    // f16é…åˆ—ã‹ã‚‰ç›´æ¥ä½œæˆ
    pub fn from_f16_slice(data: &[f16], shape: &[usize]) -> Self;

    // ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã§Metalãƒãƒƒãƒ•ã‚¡ã«å¤‰æ›
    pub fn as_metal_buffer(&self, device: &metal::Device) -> MetalBuffer;
}
```

## 2. ã‚³ã‚¢é–¢æ•°ä»•æ§˜

### 2.1 ãƒ†ãƒ³ã‚½ãƒ«ç”Ÿæˆ (Metalå®Ÿè£…)

```rust
impl Tensor {
    // ã™ã¹ã¦Metal GPUã§ç”Ÿæˆ
    pub fn zeros_metal(device: &MetalDevice, shape: Vec<usize>) -> Self {
        // Metal kernelã§ã‚¼ãƒ­åŸ‹ã‚
    }

    pub fn ones_metal(device: &MetalDevice, shape: Vec<usize>) -> Self {
        // Metal kernelã§1åŸ‹ã‚
    }

    pub fn rand_metal(device: &MetalDevice, shape: Vec<usize>) -> Self {
        // Metal kernelã§ãƒ©ãƒ³ãƒ€ãƒ ç”Ÿæˆ (f16)
    }

    pub fn from_f16_vec(device: &MetalDevice, data: Vec<f16>, shape: Vec<usize>) -> Self {
        // f16ãƒ™ã‚¯ã‚¿ã‚’ç›´æ¥Metalãƒãƒƒãƒ•ã‚¡ã«ã‚³ãƒ”ãƒ¼
    }
}
```

### 2.2 åŸºæœ¬æ¼”ç®— (Metal Shaders)

å„æ¼”ç®—ã¯Metalã‚·ã‚§ãƒ¼ãƒ€ãƒ¼ã§å®Ÿè£…ã—ã€f16ã§è¨ˆç®—ã€‚

#### Metal Shaderä¾‹: è¦ç´ ã”ã¨åŠ ç®—

```metal
// add.metal
#include <metal_stdlib>
using namespace metal;

kernel void add_f16(
    device const half* a [[buffer(0)]],
    device const half* b [[buffer(1)]],
    device half* result [[buffer(2)]],
    uint index [[thread_position_in_grid]]
) {
    result[index] = a[index] + b[index];
}
```

#### Rustå´ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

```rust
impl Tensor {
    pub fn add(&self, other: &Tensor) -> Result<Tensor, TensorError> {
        match (&self.buffer, &other.buffer) {
            (BufferHandle::Metal(a), BufferHandle::Metal(b)) => {
                // Metalã‚«ãƒ¼ãƒãƒ«å®Ÿè¡Œ
                metal_add_f16(a, b)
            },
            _ => self.to_metal()?.add(&other.to_metal()?),
        }
    }

    pub fn sub(&self, other: &Tensor) -> Result<Tensor, TensorError>;
    pub fn mul(&self, other: &Tensor) -> Result<Tensor, TensorError>;
    pub fn div(&self, other: &Tensor) -> Result<Tensor, TensorError>;
}
```

### 2.3 è¡Œåˆ—æ¼”ç®— (Neural Engineå„ªå…ˆ)

è¡Œåˆ—ç©ãªã©ã®è¤‡é›‘ãªæ¼”ç®—ã¯Neural Engineã‚’å„ªå…ˆä½¿ç”¨ã€‚

```rust
impl Tensor {
    pub fn matmul(&self, other: &Tensor) -> Result<Tensor, TensorError> {
        // Neural Engineã§å®Ÿè¡Œ
        self.to_neural_engine()?.matmul_ne(&other.to_neural_engine()?)
    }
}

// Neural Engineå®Ÿè£…
fn matmul_ne(a: &NeuralEngineBuffer, b: &NeuralEngineBuffer) -> Result<Tensor, TensorError> {
    // CoreMLãƒ¢ãƒ‡ãƒ«ã¨ã—ã¦è¡Œåˆ—ç©ã‚’å®Ÿè¡Œ
    let model = create_matmul_coreml_model(a.shape(), b.shape());
    let result = model.predict(&[a.array, b.array])?;

    // çµæœã‚’f16ãƒãƒƒãƒ•ã‚¡ã¨ã—ã¦ä¿æŒï¼ˆå¤‰æ›ãªã—ï¼‰
    Ok(Tensor::from_neural_engine(result))
}
```

### 2.4 ã‚¢ã‚¤ãƒ³ã‚·ãƒ¥ã‚¿ã‚¤ãƒ³å’Œ (ãƒã‚¤ãƒ–ãƒªãƒƒãƒ‰å®Ÿè£…)

```rust
pub fn einsum(spec: &str, tensors: &[&Tensor]) -> Result<Tensor, TensorError> {
    // ä»•æ§˜ã‚’è§£æ (CPU)
    let plan = parse_einsum_spec(spec)?;

    // å®Ÿè¡Œæˆ¦ç•¥ã‚’é¸æŠ (CPU)
    match classify_einsum_operation(&plan) {
        EinsumOp::MatMul => {
            // Neural Engineã§å®Ÿè¡Œ
            execute_matmul_ne(tensors, &plan)
        },
        EinsumOp::Transpose => {
            // Metalã§å®Ÿè¡Œ
            execute_transpose_metal(tensors[0], &plan)
        },
        EinsumOp::ElementWise => {
            // Metalã§å®Ÿè¡Œ
            execute_elementwise_metal(tensors, &plan)
        },
        EinsumOp::Complex => {
            // Metalã‚«ã‚¹ã‚¿ãƒ ã‚«ãƒ¼ãƒãƒ«ã§å®Ÿè¡Œ
            execute_custom_einsum_metal(tensors, &plan)
        },
    }
}
```

### 2.5 æ´»æ€§åŒ–é–¢æ•° (Metal Shaders)

```metal
// activation.metal
kernel void sigmoid_f16(
    device const half* input [[buffer(0)]],
    device half* output [[buffer(1)]],
    uint index [[thread_position_in_grid]]
) {
    half x = input[index];
    output[index] = half(1.0) / (half(1.0) + exp(-x));
}

kernel void relu_f16(
    device const half* input [[buffer(0)]],
    device half* output [[buffer(1)]],
    uint index [[thread_position_in_grid]]
) {
    half x = input[index];
    output[index] = max(x, half(0.0));
}
```

```rust
impl Tensor {
    pub fn sigmoid(&self) -> Tensor {
        execute_metal_kernel("sigmoid_f16", &[self.buffer])
    }

    pub fn relu(&self) -> Tensor {
        execute_metal_kernel("relu_f16", &[self.buffer])
    }

    pub fn tanh(&self) -> Tensor {
        execute_metal_kernel("tanh_f16", &[self.buffer])
    }
}
```

### 2.6 é›†ç´„æ¼”ç®— (Metal MPSä½¿ç”¨)

Metal Performance Shadersã‚’æ´»ç”¨ã€‚

```rust
use metal_performance_shaders as mps;

impl Tensor {
    pub fn sum(&self, dim: Option<usize>) -> Tensor {
        match dim {
            None => {
                // å…¨è¦ç´ ã®åˆè¨ˆ (MPS)
                mps::reduction_sum(&self.buffer)
            },
            Some(d) => {
                // ç‰¹å®šæ¬¡å…ƒã®åˆè¨ˆ (ã‚«ã‚¹ã‚¿ãƒ Metal kernel)
                metal_reduce_sum_dim(&self.buffer, d)
            },
        }
    }

    pub fn mean(&self, dim: Option<usize>) -> Tensor;
    pub fn max(&self, dim: Option<usize>) -> Tensor;
    pub fn min(&self, dim: Option<usize>) -> Tensor;
}
```

## 3. è‡ªå‹•å¾®åˆ† (Neural Engine + Metal)

### 3.1 è¨ˆç®—ã‚°ãƒ©ãƒ•

```rust
pub struct ComputationGraph {
    nodes: Vec<Node>,

    // ãƒ‡ãƒã‚¤ã‚¹æƒ…å ±
    metal_device: MetalDevice,
    use_neural_engine: bool,
}

pub struct Node {
    id: NodeId,
    operation: Operation,
    inputs: Vec<NodeId>,

    // f16ãƒãƒƒãƒ•ã‚¡
    output: BufferHandle,
    gradient: Option<BufferHandle>,
}

pub enum Operation {
    // Neural Engine ops
    MatMul,
    Conv2D,

    // Metal ops
    Add, Sub, Mul, Div,
    Sigmoid, ReLU, Tanh,

    // Custom ops
    Einsum(String),
}
```

### 3.2 å¾Œå‘ãä¼æ’­

```rust
impl ComputationGraph {
    pub fn backward(&mut self, output_grad: Tensor) -> Result<(), TensorError> {
        // ãƒˆãƒãƒ­ã‚¸ã‚«ãƒ«ã‚½ãƒ¼ãƒˆ (CPU)
        let sorted_nodes = self.topological_sort();

        // é€†é †ã«å‹¾é…è¨ˆç®— (GPU)
        for node_id in sorted_nodes.iter().rev() {
            let node = &self.nodes[node_id];

            match node.operation {
                Operation::MatMul => {
                    // Neural Engineã§å‹¾é…è¨ˆç®—
                    self.backward_matmul_ne(node)?;
                },
                Operation::Add | Operation::Mul => {
                    // Metalã§å‹¾é…è¨ˆç®—
                    self.backward_elementwise_metal(node)?;
                },
                _ => {
                    // ã‚«ã‚¹ã‚¿ãƒ Metal kernelã§å‹¾é…è¨ˆç®—
                    self.backward_custom_metal(node)?;
                },
            }
        }

        Ok(())
    }
}
```

## 4. ãƒ‡ãƒã‚¤ã‚¹é–“ã®ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼å¤‰æ›

### 4.1 å…±æœ‰ãƒ¡ãƒ¢ãƒªæˆ¦ç•¥

```rust
impl Tensor {
    // Metal â†’ Neural Engine (ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)
    pub fn to_neural_engine(&self) -> Result<Tensor, TensorError> {
        match &self.buffer {
            BufferHandle::Metal(metal_buf) => {
                // MTLBufferã‚’MLMultiArrayã§ãƒ©ãƒƒãƒ—ï¼ˆãƒ‡ãƒ¼ã‚¿ã‚³ãƒ”ãƒ¼ãªã—ï¼‰
                let ml_array = wrap_metal_buffer_as_mlmultiarray(
                    metal_buf,
                    &self.shape,
                )?;

                Ok(Tensor {
                    shape: self.shape.clone(),
                    strides: self.strides.clone(),
                    buffer: BufferHandle::NeuralEngine(ml_array),
                    device: Device::NeuralEngine,
                    grad: None,
                    requires_grad: self.requires_grad,
                })
            },
            BufferHandle::NeuralEngine(_) => Ok(self.clone()),
            BufferHandle::CPU(_) => {
                // CPUã‹ã‚‰ã®å ´åˆã®ã¿ã‚³ãƒ”ãƒ¼ãŒç™ºç”Ÿ
                self.to_metal()?.to_neural_engine()
            },
        }
    }

    // Neural Engine â†’ Metal (ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼)
    pub fn to_metal(&self) -> Result<Tensor, TensorError> {
        match &self.buffer {
            BufferHandle::NeuralEngine(ml_array) => {
                // MLMultiArrayã®å†…éƒ¨MTLBufferã‚’ç›´æ¥å‚ç…§
                let metal_buf = extract_metal_buffer_from_mlmultiarray(ml_array)?;

                Ok(Tensor {
                    shape: self.shape.clone(),
                    strides: self.strides.clone(),
                    buffer: BufferHandle::Metal(metal_buf),
                    device: Device::Metal(get_default_metal_device()),
                    grad: self.grad.clone(),
                    requires_grad: self.requires_grad,
                })
            },
            BufferHandle::Metal(_) => Ok(self.clone()),
            BufferHandle::CPU(cpu_data) => {
                // CPUã‹ã‚‰Metalã¸ã‚³ãƒ”ãƒ¼
                let metal_buf = MetalBuffer::from_f16_slice(
                    &get_default_metal_device(),
                    cpu_data,
                );

                Ok(Tensor {
                    shape: self.shape.clone(),
                    strides: self.strides.clone(),
                    buffer: BufferHandle::Metal(metal_buf),
                    device: Device::Metal(get_default_metal_device()),
                    grad: None,
                    requires_grad: self.requires_grad,
                })
            },
        }
    }
}
```

## 5. æœ€é©åŒ–æˆ¦ç•¥

### 5.1 æ¼”ç®—ã®è‡ªå‹•é…ç½®

```rust
pub struct ExecutionPlanner {
    metal_device: MetalDevice,
    neural_engine_available: bool,
}

impl ExecutionPlanner {
    pub fn select_device(&self, operation: &Operation) -> Device {
        match operation {
            // Neural EngineãŒå¾—æ„ãªæ¼”ç®—
            Operation::MatMul if self.neural_engine_available => Device::NeuralEngine,
            Operation::Conv2D if self.neural_engine_available => Device::NeuralEngine,

            // Metalã§å®Ÿè¡Œ
            Operation::Add | Operation::Sub | Operation::Mul | Operation::Div => {
                Device::Metal(self.metal_device.clone())
            },

            // ã‚«ã‚¹ã‚¿ãƒ åˆ¤å®š
            _ => self.benchmark_and_select(operation),
        }
    }
}
```

### 5.2 ãƒãƒƒãƒ•ã‚¡ãƒ—ãƒ¼ãƒ«

```rust
pub struct BufferPool {
    metal_buffers: Vec<MetalBuffer>,
    neural_engine_buffers: Vec<MLMultiArray>,
}

impl BufferPool {
    // å†åˆ©ç”¨å¯èƒ½ãªãƒãƒƒãƒ•ã‚¡ã‚’å–å¾—
    pub fn acquire_metal(&mut self, size: usize) -> MetalBuffer {
        self.metal_buffers
            .iter()
            .position(|b| b.length >= size)
            .map(|i| self.metal_buffers.swap_remove(i))
            .unwrap_or_else(|| MetalBuffer::allocate(size))
    }

    // ãƒãƒƒãƒ•ã‚¡ã‚’è¿”å´
    pub fn release_metal(&mut self, buffer: MetalBuffer) {
        self.metal_buffers.push(buffer);
    }
}
```

## 6. ã‚¨ãƒ©ãƒ¼å‡¦ç†

```rust
#[derive(Debug, thiserror::Error)]
pub enum TensorError {
    #[error("Shape mismatch: expected {expected:?}, got {actual:?}")]
    ShapeMismatch { expected: Vec<usize>, actual: Vec<usize> },

    #[error("Metal error: {0}")]
    MetalError(String),

    #[error("Neural Engine error: {0}")]
    NeuralEngineError(String),

    #[error("Device conversion error: {0}")]
    DeviceConversionError(String),

    #[error("f16 precision overflow")]
    PrecisionOverflow,
}
```

## 7. å®Ÿè£…å„ªå…ˆé †åº

### Phase 1: MetalåŸºç›¤ (å®Œäº† âœ…)
- [x] Metal deviceåˆæœŸåŒ–
- [x] f16ãƒãƒƒãƒ•ã‚¡ç®¡ç†
- [x] åŸºæœ¬æ¼”ç®—shaders (add, sub, mul, div)
- [x] ãƒ†ãƒ³ã‚½ãƒ«å‹ã¨Shapeç®¡ç†
- [x] CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å®Ÿè£…

### Phase 2: Metal GPUé«˜é€ŸåŒ– (å®Œäº† âœ…)
- [x] Metal compute shaders
- [x] KernelExecutorå®Ÿè£…
- [x] Element-wiseæ¼”ç®—ã®GPUå®Ÿè£…
- [x] ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°
- [x] ã‚¹ãƒ¬ãƒƒãƒ‰ã‚°ãƒ«ãƒ¼ãƒ—æœ€é©åŒ–

### Phase 3: é«˜åº¦ãªæ¼”ç®— (å®Œäº† âœ…)
- [x] MatMulå®Ÿè£… (2D GPU kernel)
- [x] æ´»æ€§åŒ–é–¢æ•° (ReLU, GELU, Softmax)
- [x] Broadcasting (broadcast_to, broadcast_with)
- [x] é›†ç´„æ¼”ç®— (sum, mean, max, min, sum_dim, mean_dim) - CPUå®Ÿè£…
- [x] Einsumå®Ÿè£… (å®Œäº† - è«–æ–‡å®Ÿè£…ã«é‡è¦)
- [ ] GPU kernels for reductions â†’ Phase 7.6ã¸ç§»å‹•

### Phase 4: Neural Engineçµ±åˆ (å®Œäº† âœ…)
- [x] CoreMLçµ±åˆ (objc2-core-ml)
- [x] NeuralEngineBufferå®Ÿè£… (MLMultiArray wrapper + Send/Sync)
- [x] Metal â†” Neural Engine å¤‰æ› (Phase 7.1ã§ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼å®Œäº†)
- [x] NeuralEngineOpså®Ÿè£… (matmul, relu, fused ops)
- [x] Neural Engineæ¼”ç®—ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- [x] BufferHandle::NeuralEngineå®Œå…¨å®Ÿè£… (Phase 7.3)
- [ ] CoreML model loader â†’ å°†æ¥ã®ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆå®Ÿéš›ã®Neural Engineå®Ÿè¡Œï¼‰
- [ ] å®Ÿéš›ã®Neural Engineæ¨è«– â†’ å°†æ¥ã®ãƒ•ã‚§ãƒ¼ã‚ºï¼ˆç¾åœ¨ã¯CPUãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰

### Phase 5: è‡ªå‹•å¾®åˆ† âœ… **å®Œäº†**
- [x] è¨ˆç®—ã‚°ãƒ©ãƒ•æ§‹ç¯‰ (GradNode, ComputationGraph)
- [x] å‹¾é…é–¢æ•°ãƒˆãƒ¬ã‚¤ãƒˆ (GradientFunction)
- [x] åŸºæœ¬æ¼”ç®—ã®å‹¾é… (Add, Sub, Mul, Div - ãƒ–ãƒ­ãƒ¼ãƒ‰ã‚­ãƒ£ã‚¹ãƒˆå¯¾å¿œ)
- [x] é«˜åº¦ãªæ¼”ç®—ã®å‹¾é… (MatMul, ReLU, GELU, Softmax)
- [x] Tensor API (requires_grad, backward, zero_grad, grad)
- [x] çµ±åˆãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ
- [x] å®Œå…¨ãªé€†ä¼æ’­å®Ÿè£… (Phase 6ã§å®Œäº†)
- [ ] Metal GPUå‹¾é…ã‚«ãƒ¼ãƒãƒ« - Phase 7ã¸

### Phase 6: Autogradçµ±åˆ âœ… **å®Œäº†**
- [x] æ¼”ç®—ã«è¨ˆç®—ã‚°ãƒ©ãƒ•è¨˜éŒ²ã‚’çµ±åˆ
- [x] å®Œå…¨ãªé€†ä¼æ’­å®Ÿè£…
- [x] å‹¾é…ç´¯ç©ã¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†
- [x] AutogradContext APIå®Ÿè£…
- [x] no_grad()ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
- [ ] å‹¾é…ãƒã‚§ãƒƒã‚¯ (æ•°å€¤å¾®åˆ†ã¨ã®æ¯”è¼ƒ) - Phase 7ã¸
- [ ] é«˜éšå¾®åˆ†ã‚µãƒãƒ¼ãƒˆ - Phase 7ã¸

### Phase 7: æœ€é©åŒ– âš¡ **å®Œäº† âœ…**
- [x] Metal â†” Neural Engine ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼å¤‰æ› (SharedBufferå®Ÿè£…)
- [x] ãƒãƒƒãƒ•ã‚¡ãƒ—ãƒ¼ãƒ« (BufferPoolå®Ÿè£…)
- [x] æ¼”ç®—èåˆ (operator fusion) - å®Œå…¨å®Ÿè£…å®Œäº† âœ…
- [ ] ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•é…ç½® - Phase 8ã¸å»¶æœŸï¼ˆä½å„ªå…ˆåº¦ï¼‰
- [x] Metal GPUå‹¾é…ã‚«ãƒ¼ãƒãƒ« âœ…
- [x] GPU reduction kernels âœ…

**Phase 7.1-7.6 å®Œäº†**:
- 7.1: SharedBuffer - ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼Metalâ†”Neural Engineå¤‰æ› âœ…
- 7.2: BufferPool - ãƒãƒƒãƒ•ã‚¡å†åˆ©ç”¨ã«ã‚ˆã‚‹ãƒ¡ãƒ¢ãƒªæœ€é©åŒ– âœ…
- 7.3: Operator Fusion - å®Œå…¨èåˆæ¼”ç®—å®Ÿè£… âœ…
  - **Metal GPUå®Ÿè£…**: add+relu, mul+relu, affine
  - **Neural Engineå®Ÿè£…**: add+relu, mul+relu, affine (CPUãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‰Šé™¤)
  - **BufferHandleæ‹¡å¼µ**: NeuralEngine(NeuralEngineBuffer)å®Œå…¨å¯¾å¿œ
  - **ã‚¹ãƒ¬ãƒƒãƒ‰å®‰å…¨æ€§**: unsafe impl Send/Sync for NeuralEngineBuffer
  - Metal/CPU/Neural Engine ãã‚Œãã‚Œå°‚ç”¨å®Ÿè£…
- 7.5: GPU Gradient Kernels âœ…
  - gradients.metal: åŒ…æ‹¬çš„å‹¾é…ã‚«ãƒ¼ãƒãƒ«ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
  - ReLU backward GPUå®Ÿè£… (relu_backward_f16)
  - GELU backward GPUå®Ÿè£… (gelu_backward_f16)
  - è‡ªå‹•GPU/CPUé¸æŠæ©Ÿæ§‹
  - ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰GPUå­¦ç¿’ãƒ«ãƒ¼ãƒ—å¯¾å¿œ
- 7.6: GPU Reduction Kernels âœ…
  - **Global reductions GPUå®Ÿè£…**: sum, mean, max, min (two-stage parallel reduction)
  - **æ¬¡å…ƒæŒ‡å®šreduction GPUå®Ÿè£…**: sum_dim, mean_dim (Metal kernelså®Œå…¨çµ±åˆ)
  - **reductions.metal**: 6ã¤ã®GPUã‚«ãƒ¼ãƒãƒ«å®Ÿè£… (sum/mean/max/min global + sum/mean dim)
  - **è‡ªå‹•Metal/CPU/Neural Engine dispatch**: ãƒ‡ãƒã‚¤ã‚¹ã«å¿œã˜ãŸæœ€é©å®Ÿè£…é¸æŠ
  - **ãƒ†ã‚¹ãƒˆè¿½åŠ **: test_sum_dim_metal, test_mean_dim_metal, test_max_metal, test_min_metal

**ãƒ†ã‚¹ãƒˆçµæœ**: 95/95ãƒ†ã‚¹ãƒˆæˆåŠŸ (95 lib + 6 integration - 1 ignored)

### Phase 8: é«˜åº¦ãªæœ€é©åŒ– âš¡ **å®Œäº†**
- [x] ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•é…ç½® (ExecutionPlanner) âœ…
- [x] å‹¾é…ãƒã‚§ãƒƒã‚¯ (æ•°å€¤å¾®åˆ†ã¨ã®æ¯”è¼ƒ) âœ…
- [x] é«˜éšå¾®åˆ†ã‚µãƒãƒ¼ãƒˆï¼ˆåŸºæœ¬å®Ÿè£…ï¼‰ âœ…
- [x] å®Ÿéš›ã®Neural Engineæ¨è«–ï¼ˆCoreMLãƒ¢ãƒ‡ãƒ«çµ±åˆ - åŸºæœ¬å®Ÿè£…ï¼‰ âœ…
- [x] æ¼”ç®—èåˆã®è‡ªå‹•åŒ–ï¼ˆåŸºæœ¬å®Ÿè£…ï¼‰ âœ…
- [x] ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼ˆin-placeæ¼”ç®—ï¼‰ âœ…

**Phase 8.1: ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–ï¼ˆin-placeæ¼”ç®—ï¼‰å®Œäº†**:
- **In-place element-wise operations**: add_, sub_, mul_
- **In-place activation**: relu_
- **In-place scalar operations**: add_scalar_, mul_scalar_
- **CPU/Metal/Neural Engineå¯¾å¿œ**: è‡ªå‹•ãƒ‡ãƒã‚¤ã‚¹ãƒ‡ã‚£ã‚¹ãƒ‘ãƒƒãƒ
- **ãƒ¡ãƒ¢ãƒªå‰Šæ¸›**: æ–°è¦ãƒãƒƒãƒ•ã‚¡å‰²ã‚Šå½“ã¦ä¸è¦
- **ãƒ†ã‚¹ãƒˆè¿½åŠ **: 6ã¤ã®in-placeæ“ä½œãƒ†ã‚¹ãƒˆ
- **ãƒ†ã‚¹ãƒˆçµæœ**: 101/101ãƒ†ã‚¹ãƒˆæˆåŠŸ (95 â†’ 101 lib tests)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/ops/inplace.rs](src/ops/inplace.rs): In-placeæ¼”ç®—å®Ÿè£…

**Phase 8.2: ãƒ‡ãƒã‚¤ã‚¹è‡ªå‹•é…ç½®ï¼ˆExecutionPlannerï¼‰å®Œäº†**:
- **ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ãƒ™ãƒ¼ã‚¹ã®é¸æŠ**: æ¼”ç®—ç¨®é¡ã¨ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚ºã«åŸºã¥ãæœ€é©ãƒ‡ãƒã‚¤ã‚¹é¸æŠ
- **ã‚µã‚¤ã‚ºé–¾å€¤æœ€é©åŒ–**:
  - å°è¦æ¨¡æ¼”ç®— (<1000è¦ç´ ): CPU (ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰å›é¿)
  - ä¸­è¦æ¨¡æ¼”ç®— (1000-10,000è¦ç´ ): Metal GPU (ä¸¦åˆ—åŒ–)
  - å¤§è¦æ¨¡è¡Œåˆ—æ¼”ç®— (>4,096è¦ç´ ): Metal GPU (Neural Engineã¯å°†æ¥å¯¾å¿œ)
  - å¤§è¦æ¨¡Reduction (>10,000è¦ç´ ): Metal GPU
- **ãƒ‡ã‚·ã‚¸ãƒ§ãƒ³ã‚­ãƒ£ãƒƒã‚·ãƒ¥**: åŒä¸€æ¡ä»¶ã§ã®é¸æŠçµæœã‚’å†åˆ©ç”¨
- **é¸æŠæˆ¦ç•¥**: Heuristicï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰ã€Fixedï¼ˆå›ºå®šãƒ‡ãƒã‚¤ã‚¹ï¼‰
- **çµ±è¨ˆæƒ…å ±**: ã‚­ãƒ£ãƒƒã‚·ãƒ¥çŠ¶æ³ã¨ãƒ‡ãƒã‚¤ã‚¹ä½¿ç”¨çŠ¶æ³ã®å–å¾—
- **ãƒ†ã‚¹ãƒˆè¿½åŠ **: 7ã¤ã®ExecutionPlannerãƒ†ã‚¹ãƒˆ
- **ãƒ†ã‚¹ãƒˆçµæœ**: 108/108ãƒ†ã‚¹ãƒˆæˆåŠŸ (101 â†’ 108 lib tests)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/planner/execution_planner.rs](src/planner/execution_planner.rs): ExecutionPlannerå®Ÿè£…
- [claudedocs/phase8_execution_planner_design.md](claudedocs/phase8_execution_planner_design.md): è¨­è¨ˆæ–‡æ›¸

**Phase 8.3: CoreMLãƒ¢ãƒ‡ãƒ«çµ±åˆï¼ˆåŸºæœ¬å®Ÿè£…ï¼‰å®Œäº†**:
- **CoreMLModelManager**: CoreMLãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼
- **ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿**: .mlmodel/.mlmodelcãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰å¤±æ•—æ™‚ã®é©åˆ‡ãªã‚¨ãƒ©ãƒ¼å‡¦ç†
- **ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª**: model_exists()ãƒ¡ã‚½ãƒƒãƒ‰
- **ãƒ†ã‚¹ãƒˆè¿½åŠ **: 2ã¤ã®CoreMLManagerãƒ†ã‚¹ãƒˆ
- **ãƒ†ã‚¹ãƒˆçµæœ**: 110/110ãƒ†ã‚¹ãƒˆæˆåŠŸ (108 â†’ 110 lib tests)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/device/coreml_manager.rs](src/device/coreml_manager.rs): CoreMLModelManagerå®Ÿè£…
- [claudedocs/phase8.3_coreml_integration_design.md](claudedocs/phase8.3_coreml_integration_design.md): è¨­è¨ˆæ–‡æ›¸

**åˆ¶é™äº‹é …**:
- ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã¯ objc2-core-ml ã® Send/Sync åˆ¶é™ã«ã‚ˆã‚Šå°†æ¥å®Ÿè£…ã«å»¶æœŸ
- å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«æ¨è«–å®Ÿè¡Œã¯å°†æ¥ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…ï¼ˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã¯å®Œæˆï¼‰

**Phase 8.4: è‡ªå‹•æ¼”ç®—èåˆï¼ˆåŸºæœ¬å®Ÿè£…ï¼‰å®Œäº†**:
- **FusionOptimizer**: èåˆæ©Ÿä¼šæ¤œå‡ºã¨ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
- **FusionPattern**: 3ã¤ã®èåˆãƒ‘ã‚¿ãƒ¼ãƒ³å®šç¾©
  - BinaryActivation: äºŒé …æ¼”ç®— + æ´»æ€§åŒ–é–¢æ•°
  - LinearLayer: MatMul + bias + æ´»æ€§åŒ–é–¢æ•°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
  - ScalarActivation: ã‚¹ã‚«ãƒ©ãƒ¼æ¼”ç®— + æ´»æ€§åŒ–é–¢æ•°
- **FusionConfig**: èåˆè¨­å®šã¨æœ‰åŠ¹/ç„¡åŠ¹åˆ¶å¾¡
- **Performance Tracking**: èåˆåŠ¹æœã®çµ±è¨ˆè¿½è·¡
- **ãƒ†ã‚¹ãƒˆè¿½åŠ **: 7ã¤ã®FusionOptimizerãƒ†ã‚¹ãƒˆ
- **ãƒ†ã‚¹ãƒˆçµæœ**: 117/117ãƒ†ã‚¹ãƒˆæˆåŠŸ (110 â†’ 117 lib tests)
- **Activation enumæ›´æ–°**: Hash traitè¿½åŠ ã§èåˆãƒ‘ã‚¿ãƒ¼ãƒ³ã®ãƒãƒƒã‚·ãƒ¥ãƒãƒƒãƒ—å¯¾å¿œ

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/autograd/fusion.rs](src/autograd/fusion.rs): FusionOptimizerå®Ÿè£…
- [src/ops/fused.rs](src/ops/fused.rs): Activation enumæ›´æ–°
- [claudedocs/phase8.4_automatic_fusion_design.md](claudedocs/phase8.4_automatic_fusion_design.md): è¨­è¨ˆæ–‡æ›¸

**å®Ÿè£…å†…å®¹**:
- èåˆãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºã®åŸºç›¤å®Ÿè£…
- è¨­å®šå¯èƒ½ãªæœ€å°ãƒ†ãƒ³ã‚½ãƒ«ã‚µã‚¤ã‚ºï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ1000è¦ç´ ï¼‰
- ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§ Add+ReLU, Mul+ReLU ã‚’æœ‰åŠ¹åŒ–
- çµ±è¨ˆæƒ…å ±å–å¾—APIï¼ˆå¹³å‡é«˜é€ŸåŒ–ã€ä½¿ç”¨ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰

**åˆ¶é™äº‹é …**:
- å®Ÿéš›ã®ãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºãƒ­ã‚¸ãƒƒã‚¯ã¯å°†æ¥ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…
- è¨ˆç®—ã‚°ãƒ©ãƒ•ã¸ã®èåˆé©ç”¨ã¯å°†æ¥ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¯å°†æ¥ãƒ•ã‚§ãƒ¼ã‚ºã§å®Ÿè£…

**Phase 8.5: å‹¾é…ãƒã‚§ãƒƒã‚¯ï¼ˆæ•°å€¤å¾®åˆ†ã¨ã®æ¯”è¼ƒï¼‰å®Œäº†**:
- **GradientChecker**: æ•°å€¤å¾®åˆ†ã«ã‚ˆã‚‹å‹¾é…æ¤œè¨¼
- **ä¸­å¿ƒå·®åˆ†æ³•**: é«˜ç²¾åº¦ãªæ•°å€¤å‹¾é…è¨ˆç®— `[f(x+Îµ) - f(x-Îµ)] / 2Îµ`
- **å‰æ–¹å·®åˆ†æ³•**: ã‚·ãƒ³ãƒ—ãƒ«ãªæ•°å€¤å‹¾é…è¨ˆç®— `[f(x+Îµ) - f(x)] / Îµ`
- **èª¤å·®è©•ä¾¡**: ç›¸å¯¾èª¤å·®ã¨çµ¶å¯¾èª¤å·®ã®ä¸¡æ–¹ã§ãƒã‚§ãƒƒã‚¯
- **è¨­å®šå¯èƒ½ãªè¨±å®¹èª¤å·®**: f16ç²¾åº¦ã«æœ€é©åŒ–ï¼ˆepsilon=1e-2ï¼‰
- **ãƒ†ã‚¹ãƒˆè¿½åŠ **: 4ã¤ã®GradientCheckerãƒ†ã‚¹ãƒˆ
- **ãƒ†ã‚¹ãƒˆçµæœ**: 121/121ãƒ†ã‚¹ãƒˆæˆåŠŸ (117 â†’ 121 lib tests)

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/autograd/gradcheck.rs](src/autograd/gradcheck.rs): GradientCheckerå®Ÿè£…
- [claudedocs/phase8.5_gradient_checking_design.md](claudedocs/phase8.5_gradient_checking_design.md): è¨­è¨ˆæ–‡æ›¸

**å®Ÿè£…å†…å®¹**:
- æ•°å€¤å‹¾é…è¨ˆç®—ï¼ˆä¸­å¿ƒå·®åˆ†ãƒ»å‰æ–¹å·®åˆ†ï¼‰
- è§£æçš„å‹¾é…ã¨ã®æ¯”è¼ƒãƒ»æ¤œè¨¼
- ã‚¨ãƒ©ãƒ¼çµ±è¨ˆï¼ˆæœ€å¤§ãƒ»å¹³å‡èª¤å·®ï¼‰
- è©³ç´°ã‚¨ãƒ©ãƒ¼ãƒ¬ãƒãƒ¼ãƒˆï¼ˆverbose modeï¼‰
- f16ç²¾åº¦ã«æœ€é©åŒ–ã—ãŸ epsilon ã¨è¨±å®¹èª¤å·®

**f16ç²¾åº¦å¯¾å¿œ**:
- epsilon: 1e-2ï¼ˆf16ã§ã¯1e-4ã¯å°ã•ã™ãã¦èª¤å·®ãŒå¤§ãã„ï¼‰
- relative_tolerance: 1e-2
- absolute_tolerance: 1e-3
- å˜ä¸€è¦ç´ å‡ºåŠ›ã¨å¤šè¦ç´ å‡ºåŠ›ã®è‡ªå‹•åˆ¤å®š

**Phase 8.6: é«˜éšå¾®åˆ†ã‚µãƒãƒ¼ãƒˆï¼ˆæ‹¡å¼µå®Ÿè£…ï¼‰å®Œäº†**:
- **backward_create_graph()**: è¨ˆç®—ã‚°ãƒ©ãƒ•ä½œæˆãƒ¢ãƒ¼ãƒ‰ã§ã®é€†ä¼æ’­
- **AutogradContextæ‹¡å¼µ**: create_graph ãƒ•ãƒ©ã‚°ã‚µãƒãƒ¼ãƒˆ
- **å‹¾é…ã®requires_grad**: create_graph=trueæ™‚ã«å‹¾é…ãƒ†ãƒ³ã‚½ãƒ«ãŒrequires_grad=trueã«è¨­å®š
- **Operation::Gradient**: äºŒéšå¾®åˆ†è¨ˆç®—ç”¨ã®æ–°ã—ã„æ¼”ç®—ç¨®åˆ¥
- **GradientBackward**: Hessianè¨ˆç®—å®Ÿè£…ï¼ˆAdd, Sub, Mul, Divå¯¾å¿œï¼‰
- **ãƒ†ã‚¹ãƒˆè¿½åŠ **: 6ã¤ã®é«˜éšå¾®åˆ†ãƒ†ã‚¹ãƒˆ (2 gradient_op + 4 integration)
- **ãƒ†ã‚¹ãƒˆçµæœ**: å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸ

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/autograd/node.rs](src/autograd/node.rs): Operation::Gradientè¿½åŠ 
- [src/autograd/gradients/gradient_op.rs](src/autograd/gradients/gradient_op.rs): GradientBackwardå®Ÿè£…
- [src/autograd/context.rs](src/autograd/context.rs): backward_with_graph()å®Ÿè£…
- [src/tensor/tensor.rs](src/tensor/tensor.rs): backward_create_graph()å®Ÿè£…
- [tests/test_second_derivatives.rs](tests/test_second_derivatives.rs): äºŒéšå¾®åˆ†ãƒ†ã‚¹ãƒˆ (4 tests)
- [tests/higher_order_derivatives.rs](tests/higher_order_derivatives.rs): é«˜éšå¾®åˆ†ãƒ†ã‚¹ãƒˆ
- [tests/test_backward_create_graph.rs](tests/test_backward_create_graph.rs): create_graphãƒ†ã‚¹ãƒˆ
- [claudedocs/phase8.6_full_second_order_design.md](claudedocs/phase8.6_full_second_order_design.md): å®Œå…¨è¨­è¨ˆæ–‡æ›¸
- [claudedocs/phase8.6_higher_order_derivatives_design.md](claudedocs/phase8.6_higher_order_derivatives_design.md): åŸºç¤è¨­è¨ˆæ–‡æ›¸

**å®Ÿè£…å†…å®¹**:
- create_graph ãƒ•ãƒ©ã‚°ã«ã‚ˆã‚‹å‹¾é…è¨ˆç®—æ™‚ã®è¨ˆç®—ã‚°ãƒ©ãƒ•ä½œæˆ
- backward_create_graph() ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆã‚¹ã‚«ãƒ©ãƒ¼ãƒ†ãƒ³ã‚½ãƒ«ç”¨ï¼‰
- backward_with_graph() ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆå†…éƒ¨APIï¼‰
- å‹¾é…åˆ†é…æ™‚ã®requires_gradè‡ªå‹•è¨­å®š
- Thread-local CREATE_GRAPH ãƒ•ãƒ©ã‚°ç®¡ç†

**å‹•ä½œç¢ºèª**:
- create_graph=false: é€šå¸¸ã®é€†ä¼æ’­ï¼ˆå‹¾é…ã¯requires_grad=falseï¼‰
- create_graph=true: å‹¾é…ãƒ†ãƒ³ã‚½ãƒ«ãŒrequires_grad=trueã«è¨­å®š
- ãƒ†ãƒ³ã‚½ãƒ«ãƒ¬ã‚¸ã‚¹ãƒˆãƒªã‹ã‚‰ã®å‹¾é…å–å¾—ï¼ˆé‡è¦: backwardå¾Œã«get_tensor()ã§æ›´æ–°ãŒå¿…è¦ï¼‰

**åˆ¶é™äº‹é …ï¼ˆFuture Workï¼‰**:
- å®Œå…¨ãªäºŒéšå¾®åˆ†è¨ˆç®—ã«ã¯ã€é€†ä¼æ’­è‡ªä½“ãŒè¨ˆç®—ã‚°ãƒ©ãƒ•ã‚’ä½œæˆã™ã‚‹å¿…è¦ãŒã‚ã‚‹
- ç¾åœ¨ã®å®Ÿè£…ã§ã¯å‹¾é…ã¯ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ãƒ³ã‚½ãƒ«ã¨ã—ã¦è¨­å®šã•ã‚Œã‚‹ãŸã‚ã€å‹¾é…ã®å‹¾é…ã‚’ç›´æ¥è¨ˆç®—ã§ããªã„
- test_second_derivative_simple ã¨ test_second_derivative_cubic ã¯ ignoreãƒãƒ¼ã‚¯ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
- å®Ÿè£…ã«ã¯å‹¾é…è¨ˆç®—ãƒ—ãƒ­ã‚»ã‚¹è‡ªä½“ã®OperationåŒ–ãŒå¿…è¦

**è¨­è¨ˆæ–‡æ›¸ã«å«ã¾ã‚Œã‚‹å°†æ¥ã®æ‹¡å¼µ**:
- Hessianè¡Œåˆ—è¨ˆç®—ï¼ˆå®Œå…¨ã€å¯¾è§’ã€Hessian-vector productï¼‰
- Functional API (grad(), grad2())
- Jacobianè¨ˆç®—
- é«˜éšå°é–¢æ•°ï¼ˆ3éšã€4éšã€...ï¼‰

åˆè¨ˆ: ç´„18é€±é–“ (Phase 8å®Œäº†)

---

## Phase 9: æœ€é©åŒ–ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ  âœ… å®Œäº†

**Phase 9.1: Optimizerå®Ÿè£…å®Œäº†**:
- **Optimizerãƒˆãƒ¬ã‚¤ãƒˆ**: çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ï¼ˆstep, zero_grad, lrç®¡ç†ï¼‰
- **ParamGroup**: è¤‡æ•°å­¦ç¿’ç‡ã‚µãƒãƒ¼ãƒˆã€æŸ”è»Ÿãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†
- **OptimizerState**: ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆä¿å­˜/èª­ã¿è¾¼ã¿
- **SGD**: å®Œå…¨å®Ÿè£…ï¼ˆmomentum, Nesterov, weight decayå¯¾å¿œï¼‰
- **Adam**: é©å¿œçš„å­¦ç¿’ç‡ï¼ˆAMSGrad variantå¯¾å¿œï¼‰
- **AdamW**: åˆ†é›¢weight decayï¼ˆæ¨™æº–Adamæ¯”ã§å„ªã‚ŒãŸæ­£å‰‡åŒ–ï¼‰
- **19ãƒ†ã‚¹ãƒˆæˆåŠŸ**: 8 SGD + 5 Adam + 6 AdamW

**å®Ÿè£…ãƒ•ã‚¡ã‚¤ãƒ«**:
- [src/optim/mod.rs](../src/optim/mod.rs): ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ 
- [src/optim/optimizer.rs](../src/optim/optimizer.rs): ãƒˆãƒ¬ã‚¤ãƒˆã€ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
- [src/optim/sgd.rs](../src/optim/sgd.rs): SGDå®Œå…¨å®Ÿè£…
- [src/optim/adam.rs](../src/optim/adam.rs): Adamå®Ÿè£…
- [src/optim/adamw.rs](../src/optim/adamw.rs): AdamWå®Ÿè£…
- [claudedocs/phase9.1_optimizer_design.md](../claudedocs/phase9.1_optimizer_design.md): è¨­è¨ˆæ–‡æ›¸

**ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ **:

SGD:
```
Î¸_{t+1} = Î¸_t - Î· âˆ‡L(Î¸_t)
```

Momentum:
```
v_{t+1} = Î¼ v_t + (1 - dampening) âˆ‡L(Î¸_t)
Î¸_{t+1} = Î¸_t - Î· v_{t+1}
```

Adam:
```
m_{t+1} = Î²â‚ m_t + (1-Î²â‚) âˆ‡L(Î¸_t)
v_{t+1} = Î²â‚‚ v_t + (1-Î²â‚‚) [âˆ‡L(Î¸_t)]Â²
mÌ‚ = m_{t+1} / (1 - Î²â‚^{t+1})
vÌ‚ = v_{t+1} / (1 - Î²â‚‚^{t+1})
Î¸_{t+1} = Î¸_t - Î· mÌ‚ / (âˆšvÌ‚ + Îµ)
```

AdamW (åˆ†é›¢weight decay):
```
Î¸_{t+1} = Î¸_t - Î· [mÌ‚ / (âˆšvÌ‚ + Îµ) + Î» Î¸_t]
```

**ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆf16æœ€é©åŒ–ï¼‰**:
- Adam/AdamW: Î²â‚=0.9, Î²â‚‚=0.999, Îµ=1e-3 (f16ç”¨ã«èª¿æ•´)
- SGD momentum: Î¼=0.9 (æ¨™æº–)
- AdamW weight decay: 0.01 (æ¨å¥¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)

**ç‰¹å¾´**:
- AutogradContextçµ±åˆï¼ˆãƒ¬ã‚¸ã‚¹ãƒˆãƒªãƒ™ãƒ¼ã‚¹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†ï¼‰
- mul_scalar()ãƒ˜ãƒ«ãƒ‘ãƒ¼ï¼ˆãƒ†ãƒ³ã‚½ãƒ«Ã—ã‚¹ã‚«ãƒ©ãƒ¼æ¼”ç®—ï¼‰
- é€Ÿåº¦ãƒãƒƒãƒ•ã‚¡ç®¡ç†ï¼ˆHashMap<usize, Tensor>ï¼‰
- f16ç²¾åº¦ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

---

## å®Ÿè£…å®Œäº†ã‚µãƒãƒªãƒ¼

### âœ… å®Œå…¨å®Ÿè£…æ¸ˆã¿
- **Phase 1-3**: MetalåŸºç›¤ã€åŸºæœ¬æ¼”ç®—ã€é«˜åº¦ãªæ¼”ç®—
- **Phase 5-6**: Autogradï¼ˆé€†ä¼æ’­ã€è¨ˆç®—ã‚°ãƒ©ãƒ•ï¼‰
- **Phase 7**: æœ€é©åŒ–ï¼ˆã‚¼ãƒ­ã‚³ãƒ”ãƒ¼ã€ãƒãƒƒãƒ•ã‚¡ãƒ—ãƒ¼ãƒ«ã€æ¼”ç®—èåˆã€GPUå‹¾é…ï¼‰
- **Phase 8**: é«˜åº¦ãªæ©Ÿèƒ½ï¼ˆIn-place, ExecutionPlanner, Fusion, GradCheck, äºŒéšå¾®åˆ†åŸºç¤ï¼‰
- **Phase 9.1**: Optimizerï¼ˆSGD, Adam, AdamWï¼‰

### ğŸ”„ éƒ¨åˆ†å®Ÿè£…æ¸ˆã¿
- **Phase 4**: Neural Engineçµ±åˆ
  - âœ… CoreMLåŸºç›¤ï¼ˆãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ€ãƒ¼ï¼‰
  - âœ… NeuralEngineBuffer
  - âœ… Metal â†” Neural Engineå¤‰æ›ï¼ˆSharedBufferï¼‰
  - âœ… æ¼”ç®—APIï¼ˆCPUãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ï¼‰
  - âŒ MLFeatureProviderçµ±åˆ
  - âŒ å®Ÿéš›ã®æ¨è«–å®Ÿè¡Œ
  - âŒ ComputeUnité¸æŠ
  - è©³ç´°: [claudedocs/phase4_current_status.md](../claudedocs/phase4_current_status.md)

### ğŸ“Š ãƒ†ã‚¹ãƒˆçŠ¶æ³
**åˆè¨ˆãƒ†ã‚¹ãƒˆ**: 141ãƒ†ã‚¹ãƒˆæˆåŠŸ
- Phase 1-3: 95ãƒ†ã‚¹ãƒˆ
- Phase 4: 8ãƒ†ã‚¹ãƒˆ
- Phase 5-6: 19ãƒ†ã‚¹ãƒˆ
- Phase 7: 19ãƒ†ã‚¹ãƒˆè¿½åŠ 
- Phase 8: 6ãƒ†ã‚¹ãƒˆï¼ˆgradient_op + second derivativesï¼‰
- Phase 9.1: 19ãƒ†ã‚¹ãƒˆï¼ˆoptimizersï¼‰

**ã‚«ãƒãƒ¬ãƒƒã‚¸**: ä¸»è¦æ©Ÿèƒ½å…¨ã¦ãƒ†ã‚¹ãƒˆæ¸ˆã¿

### ğŸ¯ å®Ÿç”¨æ€§è©•ä¾¡
- **å®Œå…¨å®Ÿç”¨å¯èƒ½**: âœ…
  - Metal GPUæ¼”ç®—ï¼ˆf16æœ€é©åŒ–ï¼‰
  - Autogradï¼ˆè‡ªå‹•å¾®åˆ†ï¼‰
  - Optimizerï¼ˆSGD, Adam, AdamWï¼‰
  - äºŒéšå¾®åˆ†åŸºç¤

- **åŸºç›¤å®Œæˆ**: ğŸ”§
  - Neural Engineï¼ˆæ¨è«–å®Ÿè¡Œã¯æœªå®Ÿè£…ã€åŸºç›¤ã¯å®Œæˆï¼‰

### ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§
- **f16ç²¾åº¦**: å…¨æ¼”ç®—å¯¾å¿œ
- **Metal GPU**: ä¸¦åˆ—åŒ–æœ€é©åŒ–
- **ã‚¼ãƒ­ã‚³ãƒ”ãƒ¼**: Metal â†” Neural Engine
- **æ¼”ç®—èåˆ**: ãƒ¡ãƒ¢ãƒªã‚¢ã‚¯ã‚»ã‚¹å‰Šæ¸›
- **GPUå‹¾é…**: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰GPUå­¦ç¿’

### ğŸš€ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ï¼ˆæ¨å¥¨é †ï¼‰
1. **å®Ÿç”¨ãƒ†ã‚¹ãƒˆ**: å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«å­¦ç¿’ã§æ¤œè¨¼
2. **ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯**: PyTorchç­‰ã¨ã®æ€§èƒ½æ¯”è¼ƒ
3. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: APIä½¿ç”¨ä¾‹ã€ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«
4. **Neural Engineå®Œå…¨å®Ÿè£…**: MLFeatureProviderã€æ¨è«–å®Ÿè¡Œï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰

åˆè¨ˆå®Ÿè£…æœŸé–“: ç´„20é€±é–“ï¼ˆPhase 9.1å®Œäº†æ™‚ç‚¹ï¼‰
