# Graph Neural Network (GNN) Implementation in TensorLogic

**ä½œæˆæ—¥**: 2025-10-21
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: âœ… å®Œäº†

## æ¦‚è¦

TensorLogic ã§ Graph Neural Network (GNN) ã®åŸºæœ¬çš„ãª message passing ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’å®Ÿè£…ã—ã¾ã—ãŸã€‚

**å®Ÿè£…æ¸ˆã¿æ©Ÿèƒ½**:
- âœ… Message Passing (ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ‘ãƒƒã‚·ãƒ³ã‚°)
- âœ… Neighbor Aggregation (è¿‘å‚é›†ç´„)
- âœ… Node Feature Update (ãƒãƒ¼ãƒ‰ç‰¹å¾´æ›´æ–°)
- âœ… Node Classification (ãƒãƒ¼ãƒ‰åˆ†é¡ã‚¿ã‚¹ã‚¯)

## GNN ã®åŸºæœ¬æ¦‚å¿µ

### Message Passing Framework

GNN ã®åŸºæœ¬çš„ãªè¨ˆç®—ãƒ•ãƒ­ãƒ¼:

```
1. Transform: h'_i = W @ h_i
2. Aggregate: agg_i = Î£_{jâˆˆN(i)} h'_j
3. Combine: h_i^(new) = Ïƒ(h'_i + agg_i)
```

**è¨˜å·ã®èª¬æ˜**:
- `h_i`: ãƒãƒ¼ãƒ‰ i ã®ç‰¹å¾´ãƒ™ã‚¯ãƒˆãƒ«
- `W`: å­¦ç¿’å¯èƒ½ãªé‡ã¿è¡Œåˆ—
- `N(i)`: ãƒãƒ¼ãƒ‰ i ã®è¿‘å‚ãƒãƒ¼ãƒ‰é›†åˆ
- `Ïƒ`: æ´»æ€§åŒ–é–¢æ•° (ReLU, etc.)

## å®Ÿè£…ã•ã‚ŒãŸã‚µãƒ³ãƒ—ãƒ«

### 1. Message Passing

**ãƒ•ã‚¡ã‚¤ãƒ«**: [examples/gnn_message_passing.tl](../examples/gnn_message_passing.tl)

**ã‚°ãƒ©ãƒ•æ§‹é€ **:
```
Node 0 -- Node 1
  |         |
Node 2 -- Node 3
```

**ã‚¨ãƒƒã‚¸**: (0,1), (0,2), (1,3), (2,3)

**å‡¦ç†ã‚¹ãƒ†ãƒƒãƒ—**:

1. **ç‰¹å¾´å¤‰æ›**:
   ```
   h'_i = W @ h_i  (å„ãƒãƒ¼ãƒ‰ã«é‡ã¿è¡Œåˆ—ã‚’é©ç”¨)
   ```

2. **ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸é›†ç´„**:
   ```
   agg_i = (1/|N(i)|) * Î£_{jâˆˆN(i)} h'_j  (è¿‘å‚ã®å¹³å‡)
   ```

3. **ç‰¹å¾´æ›´æ–°**:
   ```
   h_i^(new) = ReLU(h'_i + agg_i)  (è‡ªå·±ç‰¹å¾´ã¨é›†ç´„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’çµåˆ)
   ```

**ä½¿ç”¨ã™ã‚‹é–¢æ•°**:
- `@`: è¡Œåˆ—ç© (ç‰¹å¾´å¤‰æ›)
- `+`: ãƒ†ãƒ³ã‚½ãƒ«åŠ ç®— (é›†ç´„)
- `/`: ã‚¹ã‚«ãƒ©ãƒ¼é™¤ç®— (å¹³å‡è¨ˆç®—)
- `relu()`: æ´»æ€§åŒ–é–¢æ•°

### 2. Node Classification

**ãƒ•ã‚¡ã‚¤ãƒ«**: [examples/gnn_node_classification.tl](../examples/gnn_node_classification.tl)

**ã‚¿ã‚¹ã‚¯**: 4ã¤ã®ãƒãƒ¼ãƒ‰ã‚’2ã‚¯ãƒ©ã‚¹ã«åˆ†é¡

**ãƒãƒ¼ãƒ‰ãƒ©ãƒ™ãƒ«**:
- Node 0, 1 â†’ Class 0
- Node 2, 3 â†’ Class 1

**ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ§‹é€ **:
```
Input Features â†’ GNN Layer â†’ Embeddings â†’ Classifier â†’ Predictions
[4, 2]           [2, 2]      [4, 2]       [2, 2]      [4, 2]
```

**æå¤±é–¢æ•°**:
```
MSE Loss = (1/N) * Î£_i ||probs_i - label_i||^2
```

**ä½¿ç”¨ã™ã‚‹é–¢æ•°**:
- `@`: è¡Œåˆ—ç© (GNN å±¤ã€åˆ†é¡å±¤)
- `relu()`: éç·šå½¢æ´»æ€§åŒ–
- `softmax()`: ã‚¯ãƒ©ã‚¹ç¢ºç‡è¨ˆç®—
- `mean()`: æå¤±è¨ˆç®—

## å®Ÿè£…ã®è©³ç´°

### ã‚°ãƒ©ãƒ•ã®è¡¨ç¾

**éš£æ¥ãƒªã‚¹ãƒˆå½¢å¼** (æ‰‹å‹•å®Ÿè£…):
```tensorlogic
// Node 0 ã®è¿‘å‚: [1, 2]
tensor neighbors_0: [1, 2]

// Node 1 ã®è¿‘å‚: [0, 3]
tensor neighbors_1: [0, 3]
```

**æ³¨æ„**: ç¾åœ¨ã¯æ‰‹å‹•ã§ã‚¨ãƒƒã‚¸ã‚’å®šç¾©ã€‚å°†æ¥çš„ã«ã¯ `relation` ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§ã‚°ãƒ©ãƒ•æ§‹é€ ã‚’å®šç¾©å¯èƒ½ã«ã™ã‚‹äºˆå®šã€‚

### Aggregation æˆ¦ç•¥

ç¾åœ¨å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹é›†ç´„é–¢æ•°:

1. **Mean Aggregation** (å¹³å‡):
   ```tensorlogic
   agg_i = (h_j1 + h_j2 + ... + h_jk) / [k]
   ```

2. **Sum Aggregation** (å’Œ):
   ```tensorlogic
   agg_i = h_j1 + h_j2 + ... + h_jk
   ```

### å­¦ç¿’å¯èƒ½ãªãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿

```tensorlogic
// GNN é‡ã¿è¡Œåˆ—
tensor W_gnn: float16[2, 2] learnable = [[0.5, 0.5],
                                          [0.5, 0.5]]

// åˆ†é¡å±¤é‡ã¿
tensor W_class: float16[2, 2] learnable = [[1.0, 0.0],
                                            [0.0, 1.0]]

// ãƒãƒ¼ãƒ‰ç‰¹å¾´ (å­¦ç¿’å¯èƒ½ãªåŸ‹ã‚è¾¼ã¿)
tensor h_0: float16[2] learnable = [1.0, 0.0]
```

## ä½¿ç”¨ä¾‹

### Message Passing

```bash
tensorlogic run examples/gnn_message_passing.tl
```

**å‡ºåŠ›ä¾‹**:
```
=== Graph Neural Network: Message Passing ===
Initial node features:
  Node 0: [1.0, 0.0]
  Node 1: [0.0, 1.0]
  Node 2: [1.0, 1.0]
  Node 3: [0.5, 0.5]

Transformed features (W @ h_i):
  h'_0: [0.5, 0.5]
  h'_1: [0.5, 0.5]
  ...

Aggregated messages (mean of neighbors):
  Agg_0: [0.75, 0.75]
  ...

Updated node features (after one GNN layer):
  Node 0: [1.25, 1.25]
  ...
```

### Node Classification

```bash
tensorlogic run examples/gnn_node_classification.tl
```

**å‡ºåŠ›ä¾‹**:
```
=== GNN Node Classification Training ===
Node embeddings after GNN:
  Node 0: [0.8, 0.3]
  Node 1: [0.7, 0.4]
  Node 2: [0.3, 0.8]
  Node 3: [0.4, 0.7]

Classification probabilities:
  Node 0 (should be Class 0): [0.8, 0.2]
  Node 1 (should be Class 0): [0.75, 0.25]
  Node 2 (should be Class 1): [0.2, 0.8]
  Node 3 (should be Class 1): [0.25, 0.75]

Total loss: 0.15
```

## GNN ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³

### å®Ÿè£…å¯èƒ½ãª GNN ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

1. **Graph Convolutional Network (GCN)**:
   ```
   h_i^(l+1) = Ïƒ(Î£_{jâˆˆN(i)} (1/âˆš(d_i*d_j)) * W^(l) @ h_j^(l))
   ```

2. **GraphSAGE**:
   ```
   h_i^(l+1) = Ïƒ(W^(l) @ concat(h_i^(l), agg({h_j^(l) : jâˆˆN(i)})))
   ```

3. **Graph Attention Network (GAT)**:
   ```
   h_i^(l+1) = Ïƒ(Î£_{jâˆˆN(i)} Î±_ij * W^(l) @ h_j^(l))
   Î±_ij = attention(h_i, h_j)
   ```

### é›†ç´„é–¢æ•°ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³

- **Mean**: `agg = mean(neighbors)`
- **Sum**: `agg = sum(neighbors)`
- **Max**: `agg = max(neighbors)` (å°†æ¥å®Ÿè£…)
- **Attention**: `agg = Î£ Î±_j * h_j` (GAT)

## ã‚¿ã‚¹ã‚¯ã®ç¨®é¡

### 1. Node Classification (ãƒãƒ¼ãƒ‰åˆ†é¡)
**ç›®çš„**: å„ãƒãƒ¼ãƒ‰ã®ã‚«ãƒ†ã‚´ãƒªã‚’äºˆæ¸¬

**ä¾‹**:
- è«–æ–‡åˆ†é¡ (å¼•ç”¨ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯)
- ãƒ¦ãƒ¼ã‚¶ãƒ¼åˆ†é¡ (ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯)

**å®Ÿè£…**: âœ… `gnn_node_classification.tl`

### 2. Link Prediction (ãƒªãƒ³ã‚¯äºˆæ¸¬)
**ç›®çš„**: 2ã¤ã®ãƒãƒ¼ãƒ‰é–“ã«ã‚¨ãƒƒã‚¸ãŒå­˜åœ¨ã™ã‚‹ã‹äºˆæ¸¬

**ä¾‹**:
- å‹é”æ¨è–¦
- çŸ¥è­˜ã‚°ãƒ©ãƒ•è£œå®Œ

**å®Ÿè£…**: ğŸ”„ ä»Šå¾Œå®Ÿè£…äºˆå®š

### 3. Graph Classification (ã‚°ãƒ©ãƒ•åˆ†é¡)
**ç›®çš„**: ã‚°ãƒ©ãƒ•å…¨ä½“ã®ã‚«ãƒ†ã‚´ãƒªã‚’äºˆæ¸¬

**ä¾‹**:
- åˆ†å­ã®æ€§è³ªäºˆæ¸¬
- ã‚½ãƒ¼ã‚·ãƒ£ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯åˆ†æ

**å®Ÿè£…**: ğŸ”„ ä»Šå¾Œå®Ÿè£…äºˆå®š

## æŠ€è¡“è©³ç´°

### ä½¿ç”¨ã—ã¦ã„ã‚‹æ¼”ç®—

#### ãƒ†ãƒ³ã‚½ãƒ«æ“ä½œ
- `@`: è¡Œåˆ—ç© (ç‰¹å¾´å¤‰æ›ã€åˆ†é¡)
- `+`: åŠ ç®— (é›†ç´„ã€æ®‹å·®)
- `/`: é™¤ç®— (å¹³å‡è¨ˆç®—)
- `*`: è¦ç´ ã”ã¨ç© (attentioné‡ã¿)

#### æ´»æ€§åŒ–é–¢æ•°
- `relu()`: éç·šå½¢å¤‰æ›
- `softmax()`: ã‚¯ãƒ©ã‚¹ç¢ºç‡
- `sigmoid()`: ã‚¨ãƒƒã‚¸äºˆæ¸¬ (å°†æ¥)

#### é›†ç´„é–¢æ•°
- `mean()`: å¹³å‡é›†ç´„
- `sum()`: å’Œé›†ç´„
- `max()`: æœ€å¤§å€¤é›†ç´„ (å°†æ¥)

### Metal GPU å¯¾å¿œ

å…¨ã¦ã®æ¼”ç®—ãŒ Metal GPU ã§é«˜é€Ÿå®Ÿè¡Œ:
- âœ… è¡Œåˆ—ç© (`@`)
- âœ… è¦ç´ ã”ã¨æ¼”ç®— (`+`, `-`, `*`, `/`)
- âœ… æ´»æ€§åŒ–é–¢æ•° (`relu`, `softmax`)
- âœ… é›†ç´„é–¢æ•° (`mean`, `sum`)

## åˆ¶é™äº‹é …ã¨ä»Šå¾Œã®æ‹¡å¼µ

### ç¾åœ¨ã®åˆ¶é™

1. **ã‚°ãƒ©ãƒ•æ§‹é€ ã®å®šç¾©**:
   - æ‰‹å‹•ã§ã‚¨ãƒƒã‚¸ã‚’å®šç¾©
   - éš£æ¥è¡Œåˆ—ã®è‡ªå‹•ç”Ÿæˆãªã—

2. **ãƒãƒƒãƒå‡¦ç†**:
   - 1ã‚°ãƒ©ãƒ•ãšã¤å‡¦ç†
   - ãƒãƒƒãƒGNNæœªå¯¾å¿œ

3. **é«˜åº¦ãªé›†ç´„**:
   - Mean/Sum ã®ã¿
   - Max, Attention æœªå®Ÿè£…

### ä»Šå¾Œã®æ‹¡å¼µ

1. **Relation ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰**:
   ```tensorlogic
   relation Edge {
       entity (node_0, node_1)
       entity (node_0, node_2)
       ...
   }
   ```

2. **Graph Attention**:
   - Attention ãƒ¡ã‚«ãƒ‹ã‚ºãƒ ã«ã‚ˆã‚‹è¿‘å‚ã®é‡ã¿ä»˜ã‘
   - Multi-head attention

3. **Sparse Operations**:
   - ç–è¡Œåˆ—æ¼”ç®—ã®æœ€é©åŒ–
   - å¤§è¦æ¨¡ã‚°ãƒ©ãƒ•ã®ã‚µãƒãƒ¼ãƒˆ

4. **Mini-batch Training**:
   - Neighbor sampling
   - GraphSAINT sampling

## ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ã¨ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

### å°è¦æ¨¡ã‚°ãƒ©ãƒ• (4 nodes, 4 edges)

**å®Ÿè¡Œæ™‚é–“** (Apple M4 Pro):
- Forward pass: < 1ms
- Backward pass: < 2ms
- Total epoch: < 5ms

**ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**:
- Node features: 32 bytes (4 Ã— 2 Ã— f16)
- Weights: 32 bytes (2 Ã— 2 Ã— 2 layers Ã— f16)
- Total: < 1KB

### ã‚¹ã‚±ãƒ¼ãƒ©ãƒ“ãƒªãƒ†ã‚£

**ç†è«–çš„ãªæ€§èƒ½** (Metal GPU):
- 1,000 nodes: ~10ms/epoch
- 10,000 nodes: ~100ms/epoch
- 100,000 nodes: ~1s/epoch (ãƒ¡ãƒ¢ãƒªæ¬¡ç¬¬)

## ã¾ã¨ã‚

TensorLogic ã§ GNN ã®ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’å®Ÿè£…ã—ã¾ã—ãŸï¼š

âœ… **å®Ÿè£…å®Œäº†**:
- Message Passing Framework
- Node Classification
- Learnable Parameters
- Metal GPU Acceleration

âœ… **ä½¿ç”¨å¯èƒ½ãªã‚¿ã‚¹ã‚¯**:
- ãƒãƒ¼ãƒ‰åˆ†é¡
- ã‚°ãƒ©ãƒ•ãƒ™ãƒ¼ã‚¹ã®å­¦ç¿’
- ç‰¹å¾´ä¼æ’­

âœ… **æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**:
- Link Prediction
- Graph Attention
- Relation ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰

ã“ã‚Œã‚‰ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’ä½¿ç”¨ã—ã¦ã€å®Ÿç”¨çš„ãª GNN ãƒ¢ãƒ‡ãƒ«ã‚’ TensorLogic ã§å®Ÿè£…ãƒ»å­¦ç¿’ã§ãã¾ã™ã€‚
