# TensorLogic å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œçµæœã‚µãƒãƒªãƒ¼

## å®Ÿè¡Œæ—¥æ™‚
2025-10-26

## ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸€è¦§

### âœ… Rustç²¾åº¦ãƒ»æœŸå¾…å€¤ãƒ†ã‚¹ãƒˆ

#### 1. f16ç²¾åº¦ãƒ†ã‚¹ãƒˆ (`examples/test_f16_precision.rs`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- åŸºæœ¬æ¼”ç®—ã®ç²¾åº¦
- Exp/Divisionï¼ˆSoftmaxæˆåˆ†ï¼‰
- 1000å€‹ã®å€¤ã®ç´¯ç©
- 22å±¤ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³

**ä¸»è¦ãªç™ºè¦‹**:
```
Layer 0:  ç´¯ç©èª¤å·® = 0.000781
Layer 10: ç´¯ç©èª¤å·® = 0.022640
Layer 21: ç´¯ç©èª¤å·® = 0.093058
```

**çµè«–**: f16èª¤å·®ã¯å°ã•ã„ãŒç´¯ç©çš„ã€‚22å±¤ã§ç´„0.093ã®èª¤å·®ã€‚

---

#### 2. RoPEæœŸå¾…å€¤è¨ˆç®— (`examples/tests/test_rope.rs`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- Position 0ã§ã®RoPEè¨ˆç®—ï¼ˆcos(0)=1, sin(0)=0ï¼‰
- Position 1ã§ã®RoPEè¨ˆç®—
- å‘¨æ³¢æ•°ã‚¹ãƒšã‚¯ãƒˆãƒ«ï¼ˆ32æ¬¡å…ƒãƒšã‚¢ï¼‰

**ä¸»è¦ãªç™ºè¦‹**:
```
Position 0: å…¥åŠ›ãŒã»ã¼ä¿å­˜ã•ã‚Œã‚‹ï¼ˆcos=1, sin=0ï¼‰
  Pair 0: freq=1.000000, theta=0.000000
  Pair 1: freq=0.749894, theta=0.000000
  Pair 2: freq=0.562341, theta=0.000000
  Pair 3: freq=0.421697, theta=0.000000

Position 1: å›è»¢ãŒé©ç”¨ã•ã‚Œã‚‹
  Pair 0: theta=1.000000 (cos=0.540302, sin=0.841471)
  Pair 1: theta=0.749894 (cos=0.731761, sin=0.681561)
```

**çµè«–**: NeoX style RoPEã€rope_base=10000ã®æ•°å­¦çš„æ¤œè¨¼å®Œäº†ã€‚

---

#### 3. GQAæœŸå¾…å€¤è¨ˆç®— (`examples/tests/test_gqa_expansion.rs`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- 4 KV heads â†’ 32 Q headså±•é–‹
- å„KVãƒ˜ãƒƒãƒ‰ãŒ8å›è¤‡è£½ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª

**ä¸»è¦ãªç™ºè¦‹**:
```
KV head 0 (values 0-63)    â†’ Q heads 0-7
KV head 1 (values 100-163) â†’ Q heads 8-15
KV head 2 (values 200-263) â†’ Q heads 16-23
KV head 3 (values 300-363) â†’ Q heads 24-31
```

**çµè«–**: GQAå±•é–‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯æ•°å­¦çš„ã«æ­£ã—ã„ã€‚

---

### âœ… TensorLogicå®Ÿè£…ãƒ†ã‚¹ãƒˆ

#### 4. RoPEå®Ÿè£… (`examples/tests/test_rope_impl.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- RoPEé–¢æ•°ã®å®Ÿè¡Œ
- å…¥å‡ºåŠ›å½¢çŠ¶ã®ç¢ºèª

**ä¸»è¦ãªç™ºè¦‹**:
```
Input shape:  [1, 32, 64]
Output shape: [1, 32, 64]
```

**çµè«–**: RoPEå®Ÿè£…ã¯æ­£ã—ãå‹•ä½œã€‚å½¢çŠ¶å¤‰æ›ãŒæ­£ç¢ºã€‚

---

#### 5. GQAå®Ÿè£… (`examples/tests/test_gqa_impl.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- reshape â†’ broadcast_to â†’ reshape ãƒ‘ã‚¿ãƒ¼ãƒ³
- 4â†’32ãƒ˜ãƒƒãƒ‰å±•é–‹

**ä¸»è¦ãªç™ºè¦‹**:
```
Step 1: [1, 4, 64] â†’ [1, 4, 1, 64]
Step 2: [1, 4, 1, 64] â†’ [1, 4, 8, 64]
Step 3: [1, 4, 8, 64] â†’ [1, 32, 64]
```

**çµè«–**: GQAå®Ÿè£…ã¯æ­£ã—ã„ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å‹•ä½œã€‚

---

#### 6. Layer 0å½¢çŠ¶æ¤œè¨¼ (`examples/tests/dump_layer0_values.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- Layer 0ã®å…¨ã‚¹ãƒ†ãƒƒãƒ—ã§å½¢çŠ¶ã‚’æ¤œè¨¼
- Embedding â†’ RMS Norm â†’ Q/K/V â†’ RoPE â†’ GQA â†’ Attention â†’ FFN

**ä¸»è¦ãªç™ºè¦‹**:
```
ã™ã¹ã¦ã®ã‚¹ãƒ†ãƒƒãƒ—ã§æ­£ã—ã„å½¢çŠ¶:
- Embedding:        [1, 2048]
- Q/K/V:            [1, 2048]/[1, 256]/[1, 256]
- Reshape:          [1, 32, 64]/[1, 4, 64]/[1, 4, 64]
- RoPE:             [1, 32, 64]/[1, 4, 64]
- GQA expansion:    [1, 32, 64]/[1, 32, 64]
- Attention:        [1, 32, 1]
- Attention output: [1, 32, 64]
- Output proj:      [1, 2048]
- FFN:              [1, 2048]
```

**çµè«–**: Layer 0ã®å®Ÿè£…ã¯å½¢çŠ¶ãƒ¬ãƒ™ãƒ«ã§å®Œç’§ã€‚

---

#### 7. 22å±¤ãƒã‚§ãƒƒã‚¯ãƒã‚¤ãƒ³ãƒˆåˆ†æ (`examples/tests/debug_layer_outputs.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- å…¨22å±¤ã®å®Ÿè¡Œ
- Layer 0, 5, 10, 15, 20, 21ã§ã®ãƒˆãƒ¼ã‚¯ãƒ³äºˆæ¸¬

**ä¸»è¦ãªç™ºè¦‹**:
```
Layer 0:  Token  2354
Layer 5:  Token  22816
Layer 10: Token  22816
Layer 15: Token  22816
Layer 20: Token  22816
Layer 21: Token  18712
```

**çµè«–**: Layer 0ã‹ã‚‰æ—¢ã«ç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ã‚’äºˆæ¸¬ã€‚Layer 5-20ã§åæŸã€‚

---

### âœ… è¿½åŠ ã®åŸºæœ¬ãƒ†ã‚¹ãƒˆ

#### 8. Softmaxæ­£è¦åŒ– (`examples/tests/test_softmax_simple.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- å˜èª¿å¢—åŠ æ€§
- åˆè¨ˆãŒ1.0
- å‡ä¸€å…¥åŠ›ã§å‡ç­‰åˆ†å¸ƒ

**ä¸»è¦ãªç™ºè¦‹**:
```
Input:  [1, 2, 3, 4]
Output: [0.032, 0.087, 0.237, 0.644]
Sum:    1.0

Uniform: [2, 2, 2, 2]
Output:  [0.25, 0.25, 0.25, 0.25]
Sum:     1.0
```

**çµè«–**: Softmaxå®Ÿè£…ã¯æ•°å­¦çš„ã«æ­£ã—ã„ã€‚

---

#### 9. RMSNormæ•°å­¦æ¤œè¨¼ (`examples/tests/test_rmsnorm_math.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- é‡ã¿é©ç”¨
- å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«é‡ã¿ã§ã®å‹•ä½œ
- NaN/Inf ãƒã‚§ãƒƒã‚¯

**ä¸»è¦ãªç™ºè¦‹**:
```
Input:  [1, 2, 3, 4]
Weight: [0.5, 1.0, 1.5, 2.0]
Output: [0.183, 0.731, 1.644, 2.922]

Real model weight (2048æ¬¡å…ƒ): NaN/Inf ãªã—
```

**çµè«–**: RMSNormå®Ÿè£…ã¯æ­£ã—ãå‹•ä½œã€‚

---

#### 10. Token Embeddingå½¢çŠ¶ (`examples/tests/test_token_embd_shape.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- token_embd.weightå½¢çŠ¶
- output.weightå½¢çŠ¶

**ä¸»è¦ãªç™ºè¦‹**:
```
token_embd.weight: [32000, 2048]
output.weight:     [32000, 2048]
```

**çµè«–**: Embeddingé‡ã¿ã®å½¢çŠ¶ãŒæ­£ã—ã„ã€‚

---

#### 11. ãƒ¬ã‚¤ãƒ¤ãƒ¼é‡ã¿å½¢çŠ¶ (`examples/tests/test_layer_shapes.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- Layer 0ã®å…¨é‡ã¿ã®å½¢çŠ¶
- Attentioné‡ã¿
- FFNé‡ã¿

**ä¸»è¦ãªç™ºè¦‹**:
```
Attention:
  Q weight: [2048, 2048]
  K weight: [256, 2048]  (4 heads * 64 dim)
  V weight: [256, 2048]  (4 heads * 64 dim)
  O weight: [2048, 2048]

FFN:
  Gate weight: [5632, 2048]
  Up weight:   [5632, 2048]
  Down weight: [2048, 5632]
```

**çµè«–**: é‡ã¿å½¢çŠ¶ã¯æœŸå¾…é€šã‚Šã€‚

---

#### 12. ãƒ¢ãƒ‡ãƒ«åŸºæœ¬å‹•ä½œ (`examples/tests/test_model_basic.tl`)
**çµæœ**: âœ… æˆåŠŸ

**æ¤œè¨¼å†…å®¹**:
- ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰
- Embedding lookup
- Linear projection
- NaN/Inf ãƒã‚§ãƒƒã‚¯

**ä¸»è¦ãªç™ºè¦‹**:
```
Embedding: [1, 2048] - NaN/Inf ãªã—
Q projection: [1, 2048] - NaN/Inf ãªã—
```

**çµè«–**: ãƒ¢ãƒ‡ãƒ«ã®åŸºæœ¬å‹•ä½œã¯æ­£å¸¸ã€‚

---

## å…¨ä½“çš„ãªçµè«–

### âœ… å®Œå…¨ã«æ­£ã—ã„ã“ã¨

1. **å½¢çŠ¶å¤‰æ›**: ã™ã¹ã¦ã®æ“ä½œã§æ­£ã—ã„å½¢çŠ¶
2. **RoPEå®Ÿè£…**: NeoX styleã€rope_base=10000ã§æ•°å­¦çš„ã«æ­£ã—ã„
3. **GQAå®Ÿè£…**: 4â†’32å±•é–‹ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒæ­£ç¢º
4. **Softmax**: æ­£è¦åŒ–ã¨å˜èª¿æ€§ãŒæ­£ã—ã„
5. **RMSNorm**: é‡ã¿é©ç”¨ãŒæ­£ã—ã„
6. **Attention**: einsumå¼ã¨ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°ãŒæ­£ã—ã„
7. **SwiGLU**: silu(gate) * up + projectionãŒæ­£ã—ã„

### â“ æœªè§£æ±ºã®å•é¡Œ

1. **æ•°å€¤ãƒ¬ãƒ™ãƒ«ã®é•ã„**:
   - Layer 0ãŒç•°ãªã‚‹ãƒˆãƒ¼ã‚¯ãƒ³ï¼ˆ2354ï¼‰ã‚’äºˆæ¸¬
   - llama.cppã¨ã®æ¯”è¼ƒãŒå¿…è¦
   - f16ç²¾åº¦ã ã‘ã§ã¯èª¬æ˜ã§ããªã„

2. **è€ƒãˆã‚‰ã‚Œã‚‹åŸå› **:
   - GGUFé‡ã¿ã®ãƒ­ãƒ¼ãƒ‰ï¼ˆQ4_0/Q6_K dequantizationï¼‰
   - Metal GPUè¨ˆç®—ã®æ•°å€¤ç²¾åº¦
   - æ¬¡å…ƒã®é †åºï¼ˆè»¢ç½®å‡¦ç†ï¼‰
   - Tokenizerã®é•ã„

### ğŸ“Š ãƒ†ã‚¹ãƒˆçµ±è¨ˆ

- **ç·ãƒ†ã‚¹ãƒˆæ•°**: 12
- **æˆåŠŸ**: 12 (100%)
- **å¤±æ•—**: 0
- **ã‚«ãƒãƒ¬ãƒƒã‚¸**:
  - âœ… å½¢çŠ¶ãƒ¬ãƒ™ãƒ«: 100%
  - âœ… å®Ÿè£…ãƒ¬ãƒ™ãƒ«: 100%
  - â“ æ•°å€¤ãƒ¬ãƒ™ãƒ«: æœªæ¤œè¨¼

### ğŸ” æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. **llama.cppã¨ã®æ•°å€¤æ¯”è¼ƒ**:
   - åŒã˜å…¥åŠ›ã§å„ã‚¹ãƒ†ãƒƒãƒ—ã®æ•°å€¤ã‚’æ¯”è¼ƒ
   - ã©ã®æ™‚ç‚¹ã§ divergence ãŒå§‹ã¾ã‚‹ã‹ç‰¹å®š

2. **GGUFé‡ã¿ã®æ¤œè¨¼**:
   - Dequantizationã®æ­£ç¢ºæ€§
   - é‡ã¿ãƒ­ãƒ¼ãƒ‰æ™‚ã®è»¢ç½®å‡¦ç†

3. **Metal shaderã®æ¤œè¨¼**:
   - RoPE, Attention, Softmax ã®å®Ÿè£…ç¢ºèª
   - CPUå®Ÿè£…ã¨æ¯”è¼ƒ

4. **ç°¡æ˜“ã‚±ãƒ¼ã‚¹ã§ã®æ‰‹å‹•è¨ˆç®—**:
   - å°ã•ã„å…¥åŠ›ã§å…¨ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ‰‹è¨ˆç®—
   - TensorLogicã¨Pythonå‚ç…§å®Ÿè£…ã‚’æ¯”è¼ƒ
