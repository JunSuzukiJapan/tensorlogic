# Neural Engineå®Œå…¨çµ±åˆ å®Ÿè£…è¨ˆç”»

**ä½œæˆæ—¥**: 2025-10-20
**æ¨å®šå·¥æ•°**: 14-20æ™‚é–“
**å„ªå…ˆåº¦**: ä½ï¼ˆMVPã¯å‹•ä½œä¸­ã€å®Œå…¨çµ±åˆã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

---

## ğŸ“‹ æ¦‚è¦

TensorLogicã®CoreML/Neural Engineçµ±åˆã‚’å®Œæˆã•ã›ã€å®Ÿéš›ã®MLãƒ¢ãƒ‡ãƒ«ã§æ¨è«–ã‚’å®Ÿè¡Œã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

### ç¾åœ¨ã®çŠ¶æ…‹
- âœ… MLModelèª­ã¿è¾¼ã¿ï¼ˆobjc2-core-ml 0.2ï¼‰
- âœ… Tensor â†’ MLMultiArrayå¤‰æ›
- âœ… MLMultiArray â†’ Tensorå¤‰æ›
- âŒ å®Ÿéš›ã®æ¨è«–å®Ÿè¡Œï¼ˆãƒ¢ãƒƒã‚¯ã®ã‚¼ãƒ­ãƒ†ãƒ³ã‚½ãƒ«ã‚’è¿”ã™ï¼‰

### ç›®æ¨™
- âœ… å®Ÿéš›ã®MLModel.predictionFromFeatureså®Ÿè¡Œ
- âœ… ãƒ¢ãƒ‡ãƒ«ã®input/outputåã®è‡ªå‹•å–å¾—
- âœ… å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼: Tensor â†’ MLMultiArray â†’ MLFeatureValue â†’ æ¨è«– â†’ Tensor

---

## ğŸ¯ Phase 1: äº‹å‰èª¿æŸ»ï¼ˆå®Œäº†ï¼‰âœ…

**å·¥æ•°**: 1æ™‚é–“ âœ…
**çŠ¶æ…‹**: å®Œäº†

### å®Ÿæ–½å†…å®¹
- [x] objc2-core-ml 0.2ã®APIèª¿æŸ»
- [x] åˆ©ç”¨å¯èƒ½ãªã‚¯ãƒ©ã‚¹ã¨ãƒ¡ã‚½ãƒƒãƒ‰ã®ç¢ºèª
- [x] å®Ÿè£…ãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ±ºå®š

### ç¢ºèªã—ãŸAPI
```rust
// MLFeatureValue
MLFeatureValue::featureValueWithMultiArray(&MLMultiArray) -> Retained<MLFeatureValue>
feature_value.multiArrayValue() -> Option<Retained<MLMultiArray>>

// MLDictionaryFeatureProvider
MLDictionaryFeatureProvider::initWithDictionary_error(
    &NSDictionary<NSString, AnyObject>
) -> Result<Retained<Self>, NSError>

// MLModelDescription
ml_model.modelDescription() -> Retained<MLModelDescription>
description.inputDescriptionsByName() -> NSDictionary<NSString, MLFeatureDescription>
description.outputDescriptionsByName() -> NSDictionary<NSString, MLFeatureDescription>

// MLModel
ml_model.predictionFromFeatures_error(
    &ProtocolObject<dyn MLFeatureProvider>
) -> Result<ProtocolObject<dyn MLFeatureProvider>, NSError>
```

---

## ğŸ”§ Phase 2: Cargo.toml feature flagsè¨­å®š

**å·¥æ•°**: 1æ™‚é–“
**ãƒ•ã‚¡ã‚¤ãƒ«**: `Cargo.toml`
**çŠ¶æ…‹**: æœªå®Ÿè£…

### ç¾åœ¨ã®è¨­å®š
```toml
objc2-core-ml = { version = "0.2", features = ["MLMultiArray", "MLModel"] }
objc2-foundation = { version = "0.2", features = ["NSArray", "NSValue", "NSError", "NSString"] }
```

### è¿½åŠ ã™ã‚‹features

#### objc2-core-ml
```toml
objc2-core-ml = { version = "0.2", features = [
    "MLMultiArray",           # æ—¢å­˜
    "MLModel",                # æ—¢å­˜
    "MLFeatureValue",         # ğŸ†• FeatureValueä½œæˆ
    "MLFeatureProvider",      # ğŸ†• ãƒ—ãƒ­ãƒˆã‚³ãƒ«
    "MLDictionaryFeatureProvider",  # ğŸ†• å…¥åŠ›ãƒ‡ãƒ¼ã‚¿æä¾›
    "MLModelDescription",     # ğŸ†• ãƒ¢ãƒ‡ãƒ«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    "MLFeatureDescription",   # ğŸ†• å…¥åŠ›/å‡ºåŠ›æƒ…å ±
] }
```

#### objc2-foundationï¼ˆè¿½åŠ è¦å¦ç¢ºèªï¼‰
```toml
objc2-foundation = { version = "0.2", features = [
    "NSArray", "NSValue", "NSError", "NSString",  # æ—¢å­˜
    "NSDictionary",  # ğŸ†• å…¥åŠ›è¾æ›¸ä½œæˆï¼ˆæ—¢ã«ä½¿ç”¨ä¸­ãªã‚‰ä¸è¦ï¼‰
] }
```

### å®Ÿè£…æ‰‹é †
1. Cargo.tomlã‚’ç·¨é›†
2. `cargo check`ã§ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ç¢ºèª
3. featureä¾å­˜é–¢ä¿‚ã®ã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°è¿½åŠ èª¿æ•´

### æ¤œè¨¼
```bash
cargo build --lib
cargo test --lib coreml --quiet
```

---

## ğŸ“ Phase 3: MLModelDescriptionçµ±åˆ

**å·¥æ•°**: 2-3æ™‚é–“
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/coreml/model.rs`
**çŠ¶æ…‹**: æœªå®Ÿè£…

### ç›®çš„
ãƒ¢ãƒ‡ãƒ«ã®input/outputåã¨å½¢çŠ¶ã‚’è‡ªå‹•å–å¾—ã—ã€ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã•ã‚ŒãŸå€¤ã‚’å‰Šé™¤ã™ã‚‹ã€‚

### å®Ÿè£…ç®‡æ‰€
`CoreMLModel::load()` ãƒ¡ã‚½ãƒƒãƒ‰ï¼ˆsrc/coreml/model.rs:56-118ï¼‰

### ç¾åœ¨ã®ã‚³ãƒ¼ãƒ‰ï¼ˆæŠœç²‹ï¼‰
```rust
// TODO: Extract input/output shapes from model description
// For now, use default ImageNet shapes
Ok(CoreMLModel {
    name,
    path: path_str,
    input_shape: vec![1, 3, 224, 224],  // ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
    output_shape: vec![1, 1000],         // ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰
    ml_model: Some(ml_model),
})
```

### æ–°ã—ã„å®Ÿè£…

#### 1. æ§‹é€ ä½“ã®æ‹¡å¼µ
```rust
pub struct CoreMLModel {
    name: String,
    path: String,
    input_shape: Vec<usize>,
    output_shape: Vec<usize>,
    input_name: String,   // ğŸ†• å…¥åŠ›å
    output_name: String,  // ğŸ†• å‡ºåŠ›å
    #[cfg(target_os = "macos")]
    ml_model: Option<Retained<MLModel>>,
}
```

#### 2. load()ãƒ¡ã‚½ãƒƒãƒ‰ã®å®Ÿè£…
```rust
#[cfg(target_os = "macos")]
{
    use objc2_core_ml::{MLModel, MLModelDescription};
    use objc2_foundation::{NSString, NSURL};

    let ml_model = unsafe { MLModel::modelWithContentsOfURL_error(&url)? };

    // MLModelDescriptionã‚’å–å¾—
    let description = unsafe { ml_model.modelDescription() };

    // å…¥åŠ›æƒ…å ±ã‚’å–å¾—
    let input_dict = unsafe { description.inputDescriptionsByName() };
    let input_keys = unsafe { input_dict.allKeys() };

    if input_keys.count() == 0 {
        return Err(CoreMLError::ModelLoadError(
            "No input descriptions found".to_string()
        ));
    }

    // æœ€åˆã®å…¥åŠ›ã‚’ä½¿ç”¨
    let input_name = unsafe { input_keys.objectAtIndex(0) };
    let input_name_str = unsafe { input_name.as_ref().to_string() };

    let input_desc = unsafe { input_dict.objectForKey(input_name).unwrap() };
    let input_shape = extract_shape_from_description(&input_desc)?;

    // å‡ºåŠ›æƒ…å ±ã‚’å–å¾—ï¼ˆåŒæ§˜ã®å‡¦ç†ï¼‰
    let output_dict = unsafe { description.outputDescriptionsByName() };
    let output_keys = unsafe { output_dict.allKeys() };

    let output_name = unsafe { output_keys.objectAtIndex(0) };
    let output_name_str = unsafe { output_name.as_ref().to_string() };

    let output_desc = unsafe { output_dict.objectForKey(output_name).unwrap() };
    let output_shape = extract_shape_from_description(&output_desc)?;

    Ok(CoreMLModel {
        name,
        path: path_str,
        input_shape,
        output_shape,
        input_name: input_name_str,
        output_name: output_name_str,
        ml_model: Some(ml_model),
    })
}
```

#### 3. ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
```rust
#[cfg(target_os = "macos")]
fn extract_shape_from_description(
    desc: &objc2_core_ml::MLFeatureDescription
) -> CoreMLResult<Vec<usize>> {
    // MLFeatureDescriptionã‹ã‚‰å½¢çŠ¶ã‚’æŠ½å‡º
    // multiArrayConstraint().shape() ãªã©ã‹ã‚‰å–å¾—
    // å®Ÿè£…è©³ç´°ã¯MLFeatureDescriptionã®APIã«ä¾å­˜

    // ç°¡æ˜“ç‰ˆ: ã¨ã‚Šã‚ãˆãšãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå½¢çŠ¶ã‚’è¿”ã™
    // å®Œå…¨ç‰ˆã§ã¯å®Ÿéš›ã«APIã‚’å‘¼ã³å‡ºã™
    Ok(vec![1, 3, 224, 224])
}
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- å…¥åŠ›/å‡ºåŠ›ãŒå­˜åœ¨ã—ãªã„å ´åˆ
- è¤‡æ•°ã®å…¥åŠ›/å‡ºåŠ›ãŒã‚ã‚‹å ´åˆï¼ˆæœ€åˆã®ã‚‚ã®ã‚’ä½¿ç”¨ï¼‰
- å½¢çŠ¶æƒ…å ±ãŒå–å¾—ã§ããªã„å ´åˆ

### ãƒ†ã‚¹ãƒˆ
```rust
#[test]
#[cfg(target_os = "macos")]
fn test_model_description_extraction() {
    // ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦ãªã®ã§ã€å®Ÿéš›ã®ãƒ†ã‚¹ãƒˆã¯çµ±åˆãƒ†ã‚¹ãƒˆ
    // ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã§ã¯æ§‹é€ ä½“ã®ã‚¢ã‚¯ã‚»ã‚µã®ã¿ãƒ†ã‚¹ãƒˆ
}
```

---

## ğŸ”„ Phase 4: MLFeatureValueçµ±åˆ

**å·¥æ•°**: 4-6æ™‚é–“
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/coreml/conversion.rs`
**çŠ¶æ…‹**: æœªå®Ÿè£…

### ç›®çš„
MLMultiArrayã‹ã‚‰MLFeatureValueã¸ã®å¤‰æ›é–¢æ•°ã‚’è¿½åŠ ã™ã‚‹ã€‚

### æ–°è¦é–¢æ•°

#### 1. mlmultiarray_to_feature_value()
```rust
#[cfg(target_os = "macos")]
pub fn mlmultiarray_to_feature_value(
    ml_array: &objc2_core_ml::MLMultiArray
) -> CoreMLResult<objc2::rc::Retained<objc2_core_ml::MLFeatureValue>> {
    use objc2_core_ml::MLFeatureValue;

    println!("Converting MLMultiArray to MLFeatureValue");

    // MLFeatureValue::featureValueWithMultiArray ã‚’å‘¼ã³å‡ºã—
    let feature_value = unsafe {
        MLFeatureValue::featureValueWithMultiArray(ml_array)
    };

    println!("  MLFeatureValue created successfully");
    Ok(feature_value)
}
```

#### 2. feature_value_to_mlmultiarray()
```rust
#[cfg(target_os = "macos")]
pub fn feature_value_to_mlmultiarray(
    feature_value: &objc2_core_ml::MLFeatureValue
) -> CoreMLResult<objc2::rc::Retained<objc2_core_ml::MLMultiArray>> {
    println!("Extracting MLMultiArray from MLFeatureValue");

    let ml_array = unsafe {
        feature_value.multiArrayValue()
            .ok_or_else(|| CoreMLError::ConversionError(
                "FeatureValue does not contain MLMultiArray".to_string()
            ))?
    };

    println!("  MLMultiArray extracted successfully");
    Ok(ml_array)
}
```

#### 3. émacOSç‰ˆã®placeholder
```rust
#[cfg(not(target_os = "macos"))]
pub fn mlmultiarray_to_feature_value() -> CoreMLResult<()> {
    println!("MLFeatureValue conversion (non-macOS placeholder)");
    Ok(())
}
```

### tensor_to_mlmultiarray()ã®æ‹¡å¼µ
ç¾åœ¨ã®é–¢æ•°ã¯ `-> CoreMLResult<()>` ã‚’è¿”ã—ã¾ã™ãŒã€å®Ÿéš›ã®MLMultiArrayã‚’è¿”ã™ã‚ˆã†ã«å¤‰æ›´:

```rust
#[cfg(target_os = "macos")]
pub fn tensor_to_mlmultiarray(
    tensor: &Tensor
) -> CoreMLResult<objc2::rc::Retained<objc2_core_ml::MLMultiArray>> {
    // æ—¢å­˜ã®å®Ÿè£… + æœ€å¾Œã« multi_array ã‚’è¿”ã™
    Ok(multi_array)
}
```

### ãƒ†ã‚¹ãƒˆ
```rust
#[test]
#[cfg(target_os = "macos")]
fn test_mlmultiarray_to_feature_value() {
    let device = MetalDevice::new().unwrap();
    let tensor = Tensor::ones(&device, vec![1, 10]).unwrap();

    let ml_array = tensor_to_mlmultiarray(&tensor).unwrap();
    let feature_value = mlmultiarray_to_feature_value(&ml_array).unwrap();

    // FeatureValueã‹ã‚‰MLMultiArrayã‚’å–ã‚Šæˆ»ã›ã‚‹ã“ã¨ã‚’ç¢ºèª
    let recovered = feature_value_to_mlmultiarray(&feature_value).unwrap();
    assert!(recovered.is_some());
}
```

---

## ğŸ“¦ Phase 5: MLDictionaryFeatureProviderçµ±åˆ

**å·¥æ•°**: 3-4æ™‚é–“
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/coreml/model.rs`
**çŠ¶æ…‹**: æœªå®Ÿè£…

### ç›®çš„
å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’MLDictionaryFeatureProviderã¨ã—ã¦æ§‹ç¯‰ã—ã€ãƒ¢ãƒ‡ãƒ«ã«æ¸¡ã™ã€‚

### å®Ÿè£…ç®‡æ‰€
`CoreMLModel::predict()` ãƒ¡ã‚½ãƒƒãƒ‰å†…

### å®Ÿè£…ã‚³ãƒ¼ãƒ‰

#### 1. NSDictionaryä½œæˆ
```rust
use objc2_foundation::{NSDictionary, NSString};
use objc2_core_ml::{MLFeatureValue, MLDictionaryFeatureProvider};
use objc2::ProtocolObject;

// 1. Tensor â†’ MLMultiArray
let ml_array = super::conversion::tensor_to_mlmultiarray(input)?;

// 2. MLMultiArray â†’ MLFeatureValue
let feature_value = super::conversion::mlmultiarray_to_feature_value(&ml_array)?;

// 3. NSDictionaryã‚’ä½œæˆ
let input_name_ns = NSString::from_str(&self.input_name);

// AnyObjectã«ã‚­ãƒ£ã‚¹ãƒˆ
let feature_value_obj = unsafe {
    std::mem::transmute::<
        objc2::rc::Retained<MLFeatureValue>,
        objc2::rc::Retained<objc2::runtime::AnyObject>
    >(feature_value)
};

// NSDictionaryä½œæˆ
let dict = NSDictionary::from_keys_and_objects(
    &[&*input_name_ns],
    &[&*feature_value_obj],
);
```

#### 2. MLDictionaryFeatureProviderä½œæˆ
```rust
// 4. MLDictionaryFeatureProviderä½œæˆ
let input_provider = unsafe {
    let allocated = MLDictionaryFeatureProvider::alloc();
    MLDictionaryFeatureProvider::initWithDictionary_error(allocated, &dict)
        .map_err(|e| CoreMLError::ConversionError(
            format!("Failed to create feature provider: {:?}", e)
        ))?
};
```

#### 3. ProtocolObjectã¸ã®ã‚­ãƒ£ã‚¹ãƒˆ
```rust
use objc2_core_ml::MLFeatureProvider;

// 5. ProtocolObject<dyn MLFeatureProvider>ã«ã‚­ãƒ£ã‚¹ãƒˆ
let provider_protocol: &ProtocolObject<dyn MLFeatureProvider> =
    ProtocolObject::from_ref(&*input_provider);
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- NSDictionaryä½œæˆå¤±æ•—
- MLDictionaryFeatureProvideråˆæœŸåŒ–å¤±æ•—
- å‹ã‚­ãƒ£ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼

### ãƒ‡ãƒãƒƒã‚°ãƒ­ã‚°
```rust
println!("Creating MLDictionaryFeatureProvider:");
println!("  Input name: {}", self.input_name);
println!("  Feature count: 1");
```

---

## ğŸš€ Phase 6: å®Œå…¨prediction()å®Ÿè£…

**å·¥æ•°**: 4-6æ™‚é–“
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/coreml/model.rs`
**çŠ¶æ…‹**: æœªå®Ÿè£…

### ç›®çš„
ã™ã¹ã¦ã®ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚’çµ±åˆã—ã€å®Ÿéš›ã®Neural Engineæ¨è«–ã‚’å®Ÿè¡Œã™ã‚‹ã€‚

### å®Œå…¨ãªpredict()å®Ÿè£…

```rust
pub fn predict(&self, input: &Tensor) -> CoreMLResult<Tensor> {
    // å…¥åŠ›å½¢çŠ¶æ¤œè¨¼
    let input_dims = input.shape().dims();
    if input_dims != self.input_shape {
        return Err(CoreMLError::InvalidInputShape {
            expected: self.input_shape.clone(),
            actual: input_dims.to_vec(),
        });
    }

    use crate::device::MetalDevice;
    let device = MetalDevice::new().map_err(|e| CoreMLError::TensorError(e))?;

    #[cfg(target_os = "macos")]
    {
        if let Some(ref ml_model) = self.ml_model {
            use super::conversion::{tensor_to_mlmultiarray, mlmultiarray_to_feature_value};
            use objc2_foundation::{NSDictionary, NSString};
            use objc2_core_ml::{MLFeatureValue, MLDictionaryFeatureProvider, MLFeatureProvider};
            use objc2::ProtocolObject;

            println!("Running CoreML inference on Neural Engine...");
            println!("  Model: {}", self.name);
            println!("  Input: {} â†’ Output: {}", self.input_name, self.output_name);

            // Step 1: Tensor â†’ MLMultiArray
            let ml_array = tensor_to_mlmultiarray(input)?;
            println!("  âœ“ MLMultiArray created");

            // Step 2: MLMultiArray â†’ MLFeatureValue
            let feature_value = mlmultiarray_to_feature_value(&ml_array)?;
            println!("  âœ“ MLFeatureValue created");

            // Step 3: Create NSDictionary
            let input_name_ns = NSString::from_str(&self.input_name);
            let feature_value_obj = unsafe {
                std::mem::transmute::<_, objc2::rc::Retained<objc2::runtime::AnyObject>>(
                    feature_value
                )
            };
            let dict = NSDictionary::from_keys_and_objects(
                &[&*input_name_ns],
                &[&*feature_value_obj],
            );
            println!("  âœ“ Input dictionary created");

            // Step 4: Create MLDictionaryFeatureProvider
            let input_provider = unsafe {
                let allocated = MLDictionaryFeatureProvider::alloc();
                MLDictionaryFeatureProvider::initWithDictionary_error(allocated, &dict)
                    .map_err(|e| CoreMLError::ConversionError(
                        format!("Failed to create feature provider: {:?}", e)
                    ))?
            };
            println!("  âœ“ Feature provider created");

            // Step 5: Cast to ProtocolObject
            let provider_protocol: &ProtocolObject<dyn MLFeatureProvider> =
                ProtocolObject::from_ref(&*input_provider);

            // Step 6: Run prediction on Neural Engine
            println!("  â†’ Running Neural Engine inference...");
            let output_provider = unsafe {
                ml_model.predictionFromFeatures_error(provider_protocol)
                    .map_err(|e| CoreMLError::InferenceError(
                        format!("Prediction failed: {:?}", e)
                    ))?
            };
            println!("  âœ“ Neural Engine inference completed");

            // Step 7: Extract output MLFeatureValue
            let output_name_ns = NSString::from_str(&self.output_name);
            let output_value = unsafe {
                output_provider.featureValueForName(&output_name_ns)
                    .ok_or_else(|| CoreMLError::ConversionError(
                        format!("Output '{}' not found", self.output_name)
                    ))?
            };
            println!("  âœ“ Output feature extracted: {}", self.output_name);

            // Step 8: Extract MLMultiArray from output
            let output_array = unsafe {
                output_value.multiArrayValue()
                    .ok_or_else(|| CoreMLError::ConversionError(
                        "Output is not MLMultiArray".to_string()
                    ))?
            };
            println!("  âœ“ Output MLMultiArray extracted");

            // Step 9: Convert MLMultiArray back to Tensor
            let output_tensor = super::conversion::mlmultiarray_to_tensor(
                &device,
                &output_array,
                self.output_shape.clone(),
            )?;
            println!("  âœ“ Output tensor created");

            println!("=== Neural Engine inference successful ===");
            Ok(output_tensor)
        } else {
            Err(CoreMLError::ModelLoadError("No MLModel loaded".to_string()))
        }
    }

    #[cfg(not(target_os = "macos"))]
    {
        // Non-macOS: Return dummy output tensor
        println!("Running CoreML inference (non-macOS placeholder)...");
        Tensor::zeros(&device, self.output_shape.clone())
            .map_err(CoreMLError::TensorError)
    }
}
```

### ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
- å„ã‚¹ãƒ†ãƒƒãƒ—ã§ã®è©³ç´°ãªã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
- ml_modelãŒå­˜åœ¨ã—ãªã„å ´åˆ
- æ¨è«–å®Ÿè¡Œå¤±æ•—
- å‡ºåŠ›å–å¾—å¤±æ•—

### ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
- å„å¤‰æ›ã‚¹ãƒ†ãƒƒãƒ—ã®æˆåŠŸ/å¤±æ•—
- Neural Engineå®Ÿè¡Œæ™‚é–“ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- å‡ºåŠ›å½¢çŠ¶ã®æ¤œè¨¼

---

## ğŸ§ª Phase 7: ãƒ†ã‚¹ãƒˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

**å·¥æ•°**: 2-3æ™‚é–“
**ãƒ•ã‚¡ã‚¤ãƒ«**:
- `tests/coreml_integration_test.rs`
- `claudedocs/coreml_full_integration.md`
- `benchmarks/coreml_neural_engine.rs`

### çµ±åˆãƒ†ã‚¹ãƒˆ

#### 1. åŸºæœ¬æ¨è«–ãƒ†ã‚¹ãƒˆ
```rust
#[test]
#[cfg(target_os = "macos")]
fn test_full_prediction_pipeline() {
    // å®Ÿéš›ã®ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ãŒå¿…è¦
    // CI/CDã§ã¯ skip ã¾ãŸã¯ ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ä½¿ç”¨
}
```

#### 2. ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ
```rust
#[test]
fn test_invalid_model_path() {
    let result = CoreMLModel::load("nonexistent.mlmodelc");
    assert!(result.is_err());
}

#[test]
fn test_shape_mismatch() {
    // å½¢çŠ¶ä¸ä¸€è‡´ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
}
```

### ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°

#### claudedocs/coreml_full_integration.md
- å®Ÿè£…ã®è©³ç´°èª¬æ˜
- ä½¿ç”¨ä¾‹
- ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç‰¹æ€§

#### README.mdæ›´æ–°
```markdown
## CoreML/Neural Engine Support

TensorLogic supports real-time inference on Apple's Neural Engine:

```rust
use tensorlogic::coreml::CoreMLModel;

let model = CoreMLModel::load("model.mlmodelc")?;
let output = model.predict(&input_tensor)?;
```

Optimized for Apple Silicon (M1/M2/M3/M4) Neural Engine.
```

### ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯

#### benches/coreml_neural_engine.rs
```rust
fn benchmark_neural_engine_vs_metal(c: &mut Criterion) {
    // Neural Engine vs Metal GPU ã®æ€§èƒ½æ¯”è¼ƒ
}
```

---

## ğŸ“Š å·¥æ•°è¦‹ç©ã‚‚ã‚Šè©³ç´°

| Phase | ã‚¿ã‚¹ã‚¯ | æœ€å°å·¥æ•° | æœ€å¤§å·¥æ•° | å„ªå…ˆåº¦ |
|-------|--------|----------|----------|--------|
| 1 | äº‹å‰èª¿æŸ» | 1h | 1h | å®Œäº†âœ… |
| 2 | Cargo.tomlè¨­å®š | 0.5h | 1h | é«˜ |
| 3 | MLModelDescription | 2h | 3h | é«˜ |
| 4 | MLFeatureValue | 3h | 5h | é«˜ |
| 5 | MLDictionaryFeatureProvider | 2h | 4h | é«˜ |
| 6 | å®Œå…¨prediction() | 3h | 5h | é«˜ |
| 7 | ãƒ†ã‚¹ãƒˆãƒ»ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ | 2h | 3h | ä¸­ |
| **åˆè¨ˆ** | | **13.5h** | **22h** | |

**æ¨å¥¨å®Ÿæ–½é †åº**: Phase 2 â†’ 3 â†’ 4 â†’ 5 â†’ 6 â†’ 7

---

## ğŸ¯ æˆåŠŸåŸºæº–

### æ©Ÿèƒ½è¦ä»¶
- [ ] å®Ÿéš›ã®MLModelã§æ¨è«–å®Ÿè¡ŒæˆåŠŸ
- [ ] input/outputåã®è‡ªå‹•å–å¾—
- [ ] å…¥åŠ›å½¢çŠ¶æ¤œè¨¼
- [ ] ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å®Œå‚™

### æ€§èƒ½è¦ä»¶
- [ ] Neural Engineåˆ©ç”¨ç¢ºèª
- [ ] Metal GPUã¨ã®æ€§èƒ½æ¯”è¼ƒ
- [ ] ã‚ªãƒ¼ãƒãƒ¼ãƒ˜ãƒƒãƒ‰ < 10%

### å“è³ªè¦ä»¶
- [ ] å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼ˆ298+ testsï¼‰
- [ ] ã‚³ãƒ³ãƒ‘ã‚¤ãƒ©è­¦å‘Š0ä»¶
- [ ] ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆå®Œå‚™

---

## ğŸš¨ ãƒªã‚¹ã‚¯ã¨å¯¾ç­–

### ãƒªã‚¹ã‚¯1: objc2-core-ml APIåˆ¶ç´„
**å½±éŸ¿**: é«˜
**å¯¾ç­–**:
- APIèª¿æŸ»å®Œäº†ã§å¤§éƒ¨åˆ†ã®ãƒªã‚¹ã‚¯è»½æ¸›æ¸ˆã¿
- ä¸æ˜ç‚¹ã¯å®Ÿè£…ä¸­ã«æ®µéšçš„ã«è§£æ±º

### ãƒªã‚¹ã‚¯2: Neural Engineåˆ©ç”¨ã®æ¤œè¨¼å›°é›£
**å½±éŸ¿**: ä¸­
**å¯¾ç­–**:
- Activity Monitor ã§ ane ãƒ—ãƒ­ã‚»ã‚¹ç¢ºèª
- Instruments ã§ Neural Engine ä½¿ç”¨ç‡æ¸¬å®š
- ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¯”è¼ƒã§é–“æ¥çš„ã«ç¢ºèª

### ãƒªã‚¹ã‚¯3: å®Ÿè£…æ™‚é–“ã®è¶…é
**å½±éŸ¿**: ä½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³å®Ÿè£…ã®ãŸã‚ï¼‰
**å¯¾ç­–**:
- Phaseå˜ä½ã§é€²æ—ç®¡ç†
- å„Phaseå®Œäº†å¾Œã«ã‚³ãƒŸãƒƒãƒˆ
- å•é¡Œç™ºç”Ÿæ™‚ã¯æ—©æœŸã«åˆ¤æ–­

---

## ğŸ“ å®Ÿè£…ãƒ¡ãƒ¢

### unsafeä½¿ç”¨ç®‡æ‰€
- objc2ã®FFIå‘¼ã³å‡ºã—ã¯ã™ã¹ã¦unsafe
- å‹å¤‰æ›ï¼ˆtransmuteï¼‰ã¯æœ€å°é™ã«
- å„unsafe blockã«ã‚³ãƒ¡ãƒ³ãƒˆå¿…é ˆ

### ãƒ¡ãƒ¢ãƒªç®¡ç†
- Retained<T> ã‚’ä½¿ç”¨ã—ã¦ARCç®¡ç†
- æ‰‹å‹•ã§ã®releaseä¸è¦
- ãƒ©ã‚¤ãƒ•ã‚¿ã‚¤ãƒ ã«æ³¨æ„

### ã‚¯ãƒ­ã‚¹ãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ 
- #[cfg(target_os = "macos")] ã§æ¡ä»¶ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
- émacOSã§ã‚‚ãƒ“ãƒ«ãƒ‰å¯èƒ½ã‚’ç¶­æŒ
- placeholderã¯æœ€å°é™ã®å®Ÿè£…

---

## ğŸ”— å‚è€ƒè³‡æ–™

- [objc2-core-ml documentation](https://docs.rs/objc2-core-ml/0.2.2/)
- [Apple CoreML Documentation](https://developer.apple.com/documentation/coreml)
- [Neural Engine Overview](https://github.com/hollance/neural-engine)
- TensorLogicæ—¢å­˜å®Ÿè£…:
  - `src/coreml/model.rs`
  - `src/coreml/conversion.rs`
  - `benches/coreml_benchmark.rs`

---

**æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—**: Phase 2ã‹ã‚‰é †æ¬¡å®Ÿè£…é–‹å§‹
**æœ€çµ‚ç›®æ¨™**: v1.0ãƒªãƒªãƒ¼ã‚¹ã§Neural Engineå®Œå…¨å¯¾å¿œ
