# TensorLogic vs Candle å®Ÿè£…æ¯”è¼ƒ

## ã‚¯ãƒ­ãƒ¼ãƒ³å ´æ‰€

**Candleå‚ç…§ç”¨ãƒªãƒã‚¸ãƒˆãƒª**: `/tmp/candle_reference/candle/`

## 1. GGUFãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®Ÿè£…

### å…±é€šç‚¹ âœ…

ä¸¡æ–¹ã¨ã‚‚**å…¨ãåŒã˜å‡¦ç†**ã‚’å®Ÿè¡Œ:

#### Candle
**ãƒ•ã‚¡ã‚¤ãƒ«**: `/tmp/candle_reference/candle/candle-core/src/quantized/gguf_file.rs:437`
```rust
dimensions.reverse();
```

#### TensorLogic
**ãƒ•ã‚¡ã‚¤ãƒ«**: `src/model/formats/gguf.rs:227`
```rust
shape.reverse();
```

**çµè«–**: GGUFãƒ­ãƒ¼ãƒ€ãƒ¼ã®æ¬¡å…ƒåè»¢å‡¦ç†ã¯å®Œå…¨ã«ä¸€è‡´ âœ…

---

## 2. Linearå±¤ã®å®Ÿè£…

### é‡è¦ãªé•ã„ âš ï¸

#### Candle: è‡ªå‹•Transpose
**ãƒ•ã‚¡ã‚¤ãƒ«**: `/tmp/candle_reference/candle/candle-nn/src/linear.rs:43-78`

```rust
impl super::Module for Linear {
    fn forward(&self, x: &Tensor) -> candle::Result<Tensor> {
        let x = match *x.dims() {
            [b1, b2, m, k] => {
                if x.is_contiguous() {
                    let w = self.weight.t()?;  // â† è‡ªå‹•çš„ã«transpose
                    x.reshape((b1 * b2 * m, k))?
                        .matmul(&w)?
                        .reshape((b1, b2, m, ()))?
                } else {
                    let w = self.weight.broadcast_left((b1, b2))?.t()?;
                    x.matmul(&w)?
                }
            }
            [bsize, m, k] => {
                if x.is_contiguous() {
                    let w = self.weight.t()?;  // â† è‡ªå‹•çš„ã«transpose
                    x.reshape((bsize * m, k))?
                        .matmul(&w)?
                        .reshape((bsize, m, ()))?
                } else {
                    let w = self.weight.broadcast_left(bsize)?.t()?;
                    x.matmul(&w)?
                }
            }
            _ => {
                let w = self.weight.t()?;  // â† è‡ªå‹•çš„ã«transpose
                x.matmul(&w)?
            }
        };
        match &self.bias {
            None => Ok(x),
            Some(bias) => x.broadcast_add(bias),
        }
    }
}
```

**ç‰¹å¾´**:
- Linearå±¤ãŒå†…éƒ¨ã§`.t()`ï¼ˆtransposeï¼‰ã‚’**è‡ªå‹•çš„ã«**å®Ÿè¡Œ
- ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«æ˜è¨˜: `y = x@w.t() + b`
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ã§ã¯transposeã‚’æ„è­˜ã—ãªã„

#### TensorLogic: æ‰‹å‹•Transpose
**ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ä¾‹**: `examples/test_bos_transpose_greedy.tl`

```rust
fn transformer_layer(
    x: float16[?, ?],
    W_q: float16[?, ?],
    ...
) -> float16[?, ?] {
    let x_norm1 = rms_norm(x, attn_norm)

    let W_q_t = transpose(W_q)  // â† ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒæ˜ç¤ºçš„ã«transpose
    let W_k_t = transpose(W_k)
    let W_v_t = transpose(W_v)

    let Q = matmul(x_norm1, W_q_t)
    let K = matmul(x_norm1, W_k_t)
    let V = matmul(x_norm1, W_v_t)
    ...
}
```

**ç‰¹å¾´**:
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒ**æ˜ç¤ºçš„ã«**`transpose()`ã‚’å‘¼ã¶å¿…è¦ãŒã‚ã‚‹
- ã‚ˆã‚Šä½ãƒ¬ãƒ™ãƒ«ã§æŸ”è»Ÿ
- é–“é•ãˆã‚„ã™ã„ï¼ˆtransposeã‚’å¿˜ã‚Œã‚‹ã¨ã‚¨ãƒ©ãƒ¼ï¼‰

---

## 3. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ¯”è¼ƒ

### Candle

```
GGUF File [2048, 32000]
    â†“
dimensions.reverse()
    â†“
Tensor [32000, 2048]
    â†“
Linear::forward() å†…ã§è‡ªå‹• .t()
    â†“
matmul(x, W_transposed)
    â†“
æ­£ã—ã„å‡ºåŠ›
```

### TensorLogic

```
GGUF File [2048, 32000]
    â†“
shape.reverse()
    â†“
Tensor [32000, 2048]
    â†“
ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‚³ãƒ¼ãƒ‰ã§æ˜ç¤ºçš„ transpose(W)
    â†“
matmul(x, W_transposed)
    â†“
æ­£ã—ã„å‡ºåŠ›
```

---

## 4. è¨­è¨ˆæ€æƒ³ã®é•ã„

| è¦³ç‚¹ | Candle | TensorLogic |
|------|--------|-------------|
| **æŠ½è±¡åº¦** | é«˜ãƒ¬ãƒ™ãƒ«ï¼ˆLinearå±¤ï¼‰ | ä½ãƒ¬ãƒ™ãƒ«ï¼ˆç”Ÿmatmulï¼‰ |
| **å®‰å…¨æ€§** | è‡ªå‹•å‡¦ç†ã§é–“é•ã„ã«ãã„ | æ‰‹å‹•å‡¦ç†ã§é–“é•ã„ã‚„ã™ã„ |
| **æŸ”è»Ÿæ€§** | Linearå±¤ã«é™å®š | ä»»æ„ã®matmulæ“ä½œå¯èƒ½ |
| **å­¦ç¿’æ›²ç·š** | ç°¡å˜ï¼ˆtransposeã‚’æ„è­˜ä¸è¦ï¼‰ | ã‚„ã‚„é›£ï¼ˆtransposeã®ç†è§£å¿…è¦ï¼‰ |
| **ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹** | æœ€é©åŒ–ã•ã‚ŒãŸLinearå®Ÿè£… | ãƒ¦ãƒ¼ã‚¶ãƒ¼æ¬¡ç¬¬ |

---

## 5. æ—¢å­˜ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã®å•é¡Œ

### å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰ä¾‹

**ãƒ•ã‚¡ã‚¤ãƒ«**: `examples/chat_demo_full_22_layers.tl`

```rust
fn transformer_layer(...) {
    let x_norm1 = rms_norm(x, attn_norm)
    let Q = matmul(x_norm1, W_q)  // âŒ transposeãªã—
    let K = matmul(x_norm1, W_k)  // âŒ transposeãªã—
    let V = matmul(x_norm1, W_v)  // âŒ transposeãªã—
    ...
}
```

**å•é¡Œ**:
- æ¬¡å…ƒåè»¢å¾Œã€é‡ã¿ã¯`[out_features, in_features]`å½¢å¼
- `matmul(x, W)`ã¯å½¢çŠ¶ãƒŸã‚¹ãƒãƒƒãƒã¾ãŸã¯èª¤ã£ãŸè¨ˆç®—
- **transposeãŒå¿…é ˆ**

### ä¿®æ­£ç‰ˆ

**ãƒ•ã‚¡ã‚¤ãƒ«**: `examples/test_bos_transpose_greedy.tl`

```rust
fn transformer_layer(...) {
    let x_norm1 = rms_norm(x, attn_norm)

    let W_q_t = transpose(W_q)  // âœ… transposeã‚’è¿½åŠ 
    let W_k_t = transpose(W_k)
    let W_v_t = transpose(W_v)

    let Q = matmul(x_norm1, W_q_t)
    let K = matmul(x_norm1, W_k_t)
    let V = matmul(x_norm1, W_v_t)
    ...
}
```

---

## 6. æ¨å¥¨äº‹é …

### çŸ­æœŸçš„å¯¾å¿œ

1. **ã™ã¹ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£**: transposeã‚’è¿½åŠ 
2. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆæ›´æ–°**: GGUFæ¬¡å…ƒåè»¢ã¨tranposeè¦ä»¶ã‚’æ˜è¨˜
3. **ãƒ†ã‚¹ãƒˆè¿½åŠ **: transposeæœ‰ç„¡ã§ã®å‡ºåŠ›æ¯”è¼ƒ

### é•·æœŸçš„æ”¹å–„æ¡ˆ

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ A: Linearå±¤ã®å®Ÿè£…
```rust
// TensorLogicã«Linearå±¤ã‚’è¿½åŠ 
fn linear(x: Tensor, W: Tensor, bias: Option<Tensor>) -> Tensor {
    let W_t = transpose(W)
    let out = matmul(x, W_t)
    if let Some(b) = bias {
        out + b
    } else {
        out
    }
}
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- Candleã¨åŒã˜ä½¿ã„å‹æ‰‹
- transposeã‚’æ„è­˜ä¸è¦
- ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ãŒã‚·ãƒ³ãƒ—ãƒ«ã«

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- æ–°æ©Ÿèƒ½ã®è¿½åŠ ãŒå¿…è¦

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³ B: æ¬¡å…ƒåè»¢ã‚’é¸æŠçš„ã«
```rust
// ç‰¹å®šã®ãƒ†ãƒ³ã‚½ãƒ«ã ã‘åè»¢
let should_reverse = name.contains("token_embd");
if should_reverse {
    shape.reverse();
}
```

**ãƒ¡ãƒªãƒƒãƒˆ**:
- transposeãŒä¸è¦ã«ãªã‚‹å¯èƒ½æ€§

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- å‚ç…§å®Ÿè£…ï¼ˆCandleã€llama.cppï¼‰ã¨ç•°ãªã‚‹å‹•ä½œ
- ä¿å®ˆãŒå›°é›£

**æ¨å¥¨**: ã‚ªãƒ—ã‚·ãƒ§ãƒ³Aã®æ–¹ãŒå®‰å…¨ã§ä¿å®ˆã—ã‚„ã™ã„

---

## 7. å‡ºåŠ›æ¯”è¼ƒãƒ†ã‚¹ãƒˆ

### TensorLogic (transposeä¿®æ­£å¾Œ)

```bash
$ ./target/release/tl run examples/test_bos_transpose_greedy.tl
Input: [1.0000]
Sampled token (greedy): 2579
```

### llama.cpp (åŒã˜ãƒ¢ãƒ‡ãƒ«ã€ãƒ•ãƒ«ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ)

```bash
$ llama-cli -m tinyllama-1.1b-chat-q4_0.gguf -p "<|system|>..." --temp 0.0
Output: "How are you?"
```

**æ³¨æ„**:
- å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãŒç•°ãªã‚‹ãŸã‚ç›´æ¥æ¯”è¼ƒä¸å¯
- åŒã˜å…¥åŠ›ã§ã®æ¯”è¼ƒãŒå¿…è¦

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

1. åŒã˜å…¥åŠ›ã§llama.cppã‚’ãƒ†ã‚¹ãƒˆ
2. TensorLogicã¨llama.cppã®ä¸­é–“å€¤ï¼ˆembeddingsã€logitsãªã©ï¼‰ã‚’æ¯”è¼ƒ
3. æ•°å€¤çš„ãªä¸€è‡´ã‚’ç¢ºèª

---

## 8. å‚è€ƒãƒ•ã‚¡ã‚¤ãƒ«

### Candle
- **GGUFãƒ­ãƒ¼ãƒ€ãƒ¼**: `/tmp/candle_reference/candle/candle-core/src/quantized/gguf_file.rs`
- **Linearå±¤**: `/tmp/candle_reference/candle/candle-nn/src/linear.rs`
- **LLaMAå®Ÿè£…**: `/tmp/candle_reference/candle/candle-transformers/src/models/llama.rs`

### TensorLogic
- **GGUFãƒ­ãƒ¼ãƒ€ãƒ¼**: `src/model/formats/gguf.rs`
- **ã‚µãƒ³ãƒ—ãƒ«ï¼ˆä¿®æ­£æ¸ˆã¿ï¼‰**: `examples/test_bos_transpose_greedy.tl`
- **ã‚µãƒ³ãƒ—ãƒ«ï¼ˆè¦ä¿®æ­£ï¼‰**: `examples/chat_demo_full_22_layers.tl`

---

## ã¾ã¨ã‚

| é …ç›® | çŠ¶æ…‹ | å¯¾å¿œ |
|------|------|------|
| GGUFæ¬¡å…ƒåè»¢ | âœ… æ­£ã—ã„ | ãªã— |
| Embeddingé–¢æ•° | âœ… ä¿®æ­£æ¸ˆã¿ | ãªã— |
| Linearå±¤ï¼ˆtransposeï¼‰ | âš ï¸ æ‰‹å‹• | ã‚µãƒ³ãƒ—ãƒ«ä¿®æ­£å¿…è¦ |
| å‡ºåŠ›ã®æ­£ç¢ºæ€§ | ğŸ”„ æ¤œè¨¼ä¸­ | llama.cppã¨è©³ç´°æ¯”è¼ƒå¿…è¦ |

**çµè«–**:
- TensorLogicã®å®Ÿè£…ã¯**æŠ€è¡“çš„ã«æ­£ã—ã„**
- Candleã¨ã®ä¸»ãªé•ã„ã¯**æŠ½è±¡åº¦**ï¼ˆè‡ªå‹• vs æ‰‹å‹•transposeï¼‰
- ã™ã¹ã¦ã®ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰ã«`transpose()`ã‚’è¿½åŠ ã™ã‚Œã°å‹•ä½œã™ã‚‹
