================================================================================
CANDLE REFERENCE VALUE EXTRACTOR
================================================================================

Model: /Users/junsuzuki/.llm/models/tinyllama-1.1b-chat-q6_k.gguf
Device: CPU (for reference extraction)

Loading model with Candle...
Model loaded successfully!
Number of tensors: 201

## Extracting Key Tensors ##


Processing: token_embd.weight
Original GGUF shape: [32000, 2048]
GGUF dtype: Q6K

================================================================================
Tensor: token_embd.weight
================================================================================
Shape: [32000, 2048]
DType: F32

First 10 values:
[0]: 0.0000000000
[1]: 0.0000000000
[2]: 0.0000000000
[3]: 0.0000000000
[4]: 0.0000000000
[5]: -0.0000000000
[6]: -0.0000000000
[7]: 0.0000000000
[8]: 0.0000000000
[9]: 0.0000000000

Statistics:
  Sum:  -21.1069831848
  Mean: -0.0000003221
  Min:  -0.1170730591
  Max:  0.1494140625

**BOS Token (ID=1) Embedding:**
  Sum: 0.0551685691
  Mean: 0.0000269378

Processing: blk.0.attn_norm.weight
Original GGUF shape: [2048]
GGUF dtype: F32

================================================================================
Tensor: blk.0.attn_norm.weight
================================================================================
Shape: [2048]
DType: F32

First 10 values:
[0]: -0.0041809082
[1]: 0.0063171387
[2]: 0.0698242188
[3]: -0.0294189453
[4]: -0.0061340332
[5]: -0.0151977539
[6]: 0.0045776367
[7]: 0.0041503906
[8]: 0.0036315918
[9]: 0.0072021484

Statistics:
  Sum:  11.8375186920
  Mean: 0.0057800384
  Min:  -0.5820312500
  Max:  0.7695312500

Processing: blk.0.attn_q.weight
Original GGUF shape: [2048, 2048]
GGUF dtype: Q6K

================================================================================
Tensor: blk.0.attn_q.weight
================================================================================
Shape: [2048, 2048]
DType: F32

First 10 values:
[0]: -0.0013418198
[1]: -0.0022363663
[2]: -0.0076036453
[3]: -0.0138654709
[4]: -0.0026836395
[5]: -0.0026836395
[6]: 0.0008945465
[7]: -0.0031309128
[8]: 0.0013418198
[9]: 0.0138654709

Statistics:
  Sum:  -32.4985237122
  Mean: -0.0000077483
  Min:  -1.5855712891
  Max:  1.0321350098

Processing: blk.0.attn_k.weight
Original GGUF shape: [256, 2048]
GGUF dtype: Q6K

================================================================================
Tensor: blk.0.attn_k.weight
================================================================================
Shape: [256, 2048]
DType: F32

First 10 values:
[0]: -0.0030963421
[1]: 0.0030963421
[2]: -0.0196101665
[3]: 0.0319955349
[4]: -0.0051605701
[5]: 0.0103211403
[6]: -0.0000000000
[7]: -0.0051605701
[8]: 0.0020642281
[9]: -0.0154817104

Statistics:
  Sum:  -51.6219749451
  Mean: -0.0000984611
  Min:  -3.1087036133
  Max:  1.1806640625

Processing: blk.0.attn_v.weight
Original GGUF shape: [256, 2048]
GGUF dtype: Q6K

================================================================================
Tensor: blk.0.attn_v.weight
================================================================================
Shape: [256, 2048]
DType: F32

First 10 values:
[0]: 0.0283813477
[1]: 0.0059127808
[2]: -0.0000000000
[3]: -0.0059127808
[4]: 0.0070953369
[5]: -0.0082778931
[6]: 0.0070953369
[7]: -0.0153732300
[8]: 0.0366592407
[9]: -0.0011825562

Statistics:
  Sum:  5.7936120033
  Mean: 0.0000110504
  Min:  -0.0674057007
  Max:  0.0620117188

Processing: output_norm.weight
Original GGUF shape: [2048]
GGUF dtype: F32

================================================================================
Tensor: output_norm.weight
================================================================================
Shape: [2048]
DType: F32

First 10 values:
[0]: 1.9218750000
[1]: 1.8203125000
[2]: 1.9453125000
[3]: 1.9843750000
[4]: 1.9140625000
[5]: 1.9062500000
[6]: 1.9140625000
[7]: 1.6640625000
[8]: 1.9296875000
[9]: 1.9765625000

Statistics:
  Sum:  3921.6875000000
  Mean: 1.9148864746
  Min:  0.5078125000
  Max:  3.1875000000

================================================================================
âœ… Reference extraction complete
================================================================================
