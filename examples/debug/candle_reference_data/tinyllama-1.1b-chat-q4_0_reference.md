================================================================================
CANDLE REFERENCE VALUE EXTRACTOR
================================================================================

Model: /Users/junsuzuki/.llm/models/tinyllama-1.1b-chat-q4_0.gguf
Device: CPU (for reference extraction)

Loading model with Candle...
Model loaded successfully!
Number of tensors: 201

## Extracting Key Tensors ##


Processing: token_embd.weight
Original GGUF shape: [32000, 2048]
GGUF dtype: Q4_0

================================================================================
Tensor: token_embd.weight
================================================================================
Shape: [32000, 2048]
DType: F32

First 10 values:
[0]: 0.0000057220
[1]: 0.0000038147
[2]: 0.0000038147
[3]: 0.0000095367
[4]: 0.0000038147
[5]: -0.0000057220
[6]: -0.0000057220
[7]: 0.0000095367
[8]: 0.0000114441
[9]: 0.0000057220

Statistics:
  Sum:  -9.7052574158
  Mean: -0.0000001481
  Min:  -0.1171875000
  Max:  0.1494140625

**BOS Token (ID=1) Embedding:**
  Sum: 0.0620975494
  Mean: 0.0000303211

Processing: blk.0.attn_norm.weight
Original GGUF shape: [2048]
GGUF dtype: F32

================================================================================
Tensor: blk.0.attn_norm.weight
================================================================================
Shape: [2048]
DType: F32

First 10 values:
[0]: -0.0041809082
[1]: 0.0063171387
[2]: 0.0698242188
[3]: -0.0294189453
[4]: -0.0061340332
[5]: -0.0151977539
[6]: 0.0045776367
[7]: 0.0041503906
[8]: 0.0036315918
[9]: 0.0072021484

Statistics:
  Sum:  11.8375186920
  Mean: 0.0057800384
  Min:  -0.5820312500
  Max:  0.7695312500

Processing: blk.0.attn_q.weight
Original GGUF shape: [2048, 2048]
GGUF dtype: Q4_0

================================================================================
Tensor: blk.0.attn_q.weight
================================================================================
Shape: [2048, 2048]
DType: F32

First 10 values:
[0]: -0.0017547607
[1]: -0.0017547607
[2]: -0.0070190430
[3]: -0.0140380859
[4]: -0.0035095215
[5]: -0.0035095215
[6]: 0.0017547607
[7]: -0.0035095215
[8]: 0.0017547607
[9]: 0.0122833252

Statistics:
  Sum:  -25.3212356567
  Mean: -0.0000060371
  Min:  -1.5859375000
  Max:  1.0312500000

Processing: blk.0.attn_k.weight
Original GGUF shape: [256, 2048]
GGUF dtype: Q4_0

================================================================================
Tensor: blk.0.attn_k.weight
================================================================================
Shape: [256, 2048]
DType: F32

First 10 values:
[0]: -0.0039978027
[1]: 0.0039978027
[2]: -0.0199890137
[3]: 0.0319824219
[4]: -0.0039978027
[5]: 0.0079956055
[6]: -0.0000000000
[7]: -0.0039978027
[8]: -0.0000000000
[9]: -0.0159912109

Statistics:
  Sum:  -49.8968544006
  Mean: -0.0000951707
  Min:  -3.1093750000
  Max:  1.1796875000

Processing: blk.0.attn_v.weight
Original GGUF shape: [256, 2048]
GGUF dtype: Q4_0

================================================================================
Tensor: blk.0.attn_v.weight
================================================================================
Shape: [256, 2048]
DType: F32

First 10 values:
[0]: 0.0274658203
[1]: 0.0045776367
[2]: -0.0000000000
[3]: -0.0045776367
[4]: 0.0091552734
[5]: -0.0091552734
[6]: 0.0045776367
[7]: -0.0137329102
[8]: 0.0366210938
[9]: -0.0000000000

Statistics:
  Sum:  5.4146385193
  Mean: 0.0000103276
  Min:  -0.0673828125
  Max:  0.0620117188

Processing: output_norm.weight
Original GGUF shape: [2048]
GGUF dtype: F32

================================================================================
Tensor: output_norm.weight
================================================================================
Shape: [2048]
DType: F32

First 10 values:
[0]: 1.9218750000
[1]: 1.8203125000
[2]: 1.9453125000
[3]: 1.9843750000
[4]: 1.9140625000
[5]: 1.9062500000
[6]: 1.9140625000
[7]: 1.6640625000
[8]: 1.9296875000
[9]: 1.9765625000

Statistics:
  Sum:  3921.6875000000
  Mean: 1.9148864746
  Min:  0.5078125000
  Max:  3.1875000000

================================================================================
âœ… Reference extraction complete
================================================================================
